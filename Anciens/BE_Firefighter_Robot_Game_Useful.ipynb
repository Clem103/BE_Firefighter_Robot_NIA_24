{"cells":[{"cell_type":"markdown","metadata":{"id":"QLm1fYp-Jvb1"},"source":["<h1><center>Graded practical work (12h)</center></h1>\n","\n","William Angelier et Marine de Fontenay"]},{"cell_type":"markdown","metadata":{"id":"FU0b7sw5Jvb2"},"source":["# INTRODUCTION"]},{"cell_type":"markdown","metadata":{"id":"WMHPS3H-Jvb2"},"source":["### Objective\n","\n","Set up a simple yet effective POMDP model in order to drive human-machine interaction in the Firefighter Robot Game study case. This POMDP model will be based on a dataset that has been collected during an experiment and that is provided to you."]},{"cell_type":"markdown","metadata":{"id":"RhbV7TSoJvb2"},"source":["### Recall: the POMDP model\n","\n","Let's recall that a POMDP (Partially Observable Markov Decision Process) is a tuple $\\langle S, A, \\Omega, p(), o(), r(), b_0 \\rangle$, with $S$ (resp. $A$, $\\Omega$) the state (resp. action, observation) space.\n","How does this probabilistic planning model work?\n","1. At each time step $t \\in \\mathbb{N}$, the artificial agent has only a partial knowledge of the actual current state $s \\in S$. In order to still be able to reason about the state of the system, the agent maintains a probability distribution over $S$, called belief state, and denoted by $b_t$. The initial belief state is $b_0$ and takes part in the definition of the POMDP as a prior distribution about the initial state.\n","2. When the artificial agent selects an action $a \\in A$, the probability that the state of the system switches from $s \\in S$ to $s' \\in S$, is $Pr(s'\\mid s,a) = p(s,a,s')$ given by the transition probability function $p()$ in the POMDP definition.\n","3. The current state is not available to the artificial agent, but the latter still receives information given by the observation $o' \\in \\Omega$. The probability that the observation $o' \\in \\Omega$ is received, is $Pr(o'\\mid s',a) = o(a,s',o')$ given by the observation probability function $o()$. \n","4. An action $a$ applied in a state $s$ is rewarded by $r(s,a) \\in \\mathbb{R}$ given by the reward function $r()$.\n","\n","![POMDP_for_HRI.png](attachment:POMDP_for_HRI.png)\n"]},{"cell_type":"markdown","metadata":{"id":"PzoZzWvtJvb3"},"source":["#### The belief state:\n","1. In partially observable domains, only successive actions and observations are visible to the agent to implement the state estimation. These sequences can be seen as the agent's memory.\n","2. Let's define the history of all observations received and actions performed at time step $t \\in \\mathbb{N}$: $h_t := \\{a_0, o_1,...,o_{t-1},a_{t-1},o_t\\}$. The size of the history grows with the time step $t \\in \\mathbb{N}$, so it can become huge very quickly.\n","3. The definition of the belief state at time step $t \\in \\mathbb{N}$ is the probability of the current state $s_t \\in S$ given the history $h_t$: $b_t(s) = Pr(s_t = s \\mid h_t)$.\n","\n","However, in practice, it is not necessary to keep the history in memory to compute the belief state. It is indeed possible to simply update the previous belief state using the action performed, and the observation received:\n","\\begin{eqnarray*}\n","{b_{t+1}(s')} & = & Pr(s' \\mid h_{t+1}) = Pr(s' \\mid  h_t, a_t, o_{t+1})\n"," = \\dfrac{Pr(o_{t+1},s' \\mid h_t,a_t)}{Pr(o_{t+1} \\mid h_t,a_t)} \\nonumber \\\\\n","& = & \\dfrac{Pr(o_{t+1} \\mid s', a_t) Pr(s' \\mid h_t,a_t) }{Pr(o_{t+1} \\mid h_t, a_t)} \n","= \\dfrac{o(a_t, s', o_{t+1}) Pr(s' \\mid h_t,a_t) }{Pr(o_{t+1} \\mid h_t,a_t)} \\nonumber \\\\\n","& = & \\dfrac{ o(a_t, s', o_{t+1}) \\sum_{s \\in S} Pr(s' \\mid s, a_t) Pr(s \\mid h_t) }{ Pr(o_{t+1} \\mid h_t,a_t)} \n","= \\dfrac{ o(a_t, s', o_{t+1}) \\sum_{s \\in S}p(s,a_t,s') b_t(s) }{ Pr(o_{t+1} \\mid h_t,a_t)} \\nonumber \\\\\n","& = & \\dfrac{ o(a_t, s', o_{t+1}) \\sum_{s \\in S}p(s,a_t,s') b_t(s) }{ \\sum_{(s,s') \\in S^2} o(a_t, s', o_{t+1}) p(s,a_t,s') b_t(s) } \\nonumber = U(b_t,a_t,o_{t+1})(s').\n","%{b_o^a(s')} & = & p(s' \\mid b,a,o) = \\dfrac{p(o,s' \\mid b,a)}{p(o \\mid b,a)} \\nonumber \\\\\n","%& = &\\dfrac{p(o \\mid s',a)p(s' \\mid b,a)}{p(o \\mid b,a)}\\nonumber \\\\\n","%& = &\\dfrac{p(o \\mid s',a)p(s' \\mid b,a)}{\\sum_{s,s'}p(o \\mid b,a,s,s')p(s,s'\\mid b,a)}\\nonumber\\\\\n","%& = &\\dfrac{p(o \\mid s',a)\\sum_{s\\in S} p(s' \\mid s,a)b(s)\n","%}{\\sum_{s'\\in S}p(o \\mid s',a)\\sum_{s\\in S} p(s'\\mid s,a)b(s)}\n","\\label{beliefupdate}\n","\\end{eqnarray*}\n","The belief update function $U$ can be defined using transition and observation functions $p()$ and $o()$. When the artificial agent uses action $a_t$ and receives observation $o_{t+1}$, it can use $b_{t+1} = U(a_t,o_{t+1},b_t)$ as belief on the system state $s_{t+1}$. Now, if the belief state is $b_t$, and the selected action is $a_t$, the probability of obtaining the belief state $b_{t+1} = U(b_t,a_t,o_{t+1})$ is the following:\n","\\begin{eqnarray*}\n","Pr(o_{t+1} \\mid  h_t, a_t) & = & \\sum_{s' \\in S} Pr(o_{t+1} \\mid s', a_t) Pr(s' \\mid h_t) = \\sum_{(s,s') \\in S^2} Pr(o_{t+1} \\mid s', a_t) Pr(s' \\mid s, a_t) Pr(s \\mid h_t)\\\\ \n","& = & \\sum_{(s,s') \\in S^2} o(a_t, s', o') p(s, a_t, s') b_t(s).\n","\\end{eqnarray*}\n","Since the probability distribution on the next belief $b_{t+1}$ only depends on the previous belief $b_t$ and the current action $a_t$, the belief state process $(b_t)_{t \\in \\mathbb{N}}$ is a Markov Decision Process (MDP) whose system space is the space of probability distributions. As a result, a POMDP can be transformed into a belief state MDP.\n","\n","In short, the artificial agent synthesizes all available information from the past using a belief state $b_t(s)$, which is a probability distribution on the system state updated every time step: $b_t(s) := Pr(s_t=s|o_t,a_{t-1},o_{t-1},..., a_0) = U(a_{t-1},o_t,b_{t-1})(s)$."]},{"cell_type":"markdown","metadata":{"id":"OK-QLcTpJvb3"},"source":["#### POMDP solving objective\n","\n","The agent's objective is to choose actions that will drive him to achieve better rewards. Let's define a deterministic Markovian policy $\\pi(b)$ as a function such as, $\\pi (b): b\\mapsto a$. The expected value of a given action policy $\\pi (b)$ can be formilized as:\n","\n","$V^{\\pi}(b) = E_\\pi\\left[\\sum ^{\\infty} _{t=0} \\gamma ^{t} r(b_t,\\pi(b_t)) \\middle\\vert b_0=b\\right]$\n","\n","where,  $0 \\leqslant \\gamma < 1$, and $r(b_t,\\pi(b_t))=\\sum_{s\\in S}r(s,\\pi(b_t))b_t(s)$\n","\n","In the POMDP context, we search for the optimal policy $\\pi^*(b)$ that maximizes the expectation of *the sum of discounted rewards* ($\\gamma$-discounted criteron). \n","\n","$V^{\\pi^*}(b) = \\max_\\pi E_\\pi\\left[\\sum ^{\\infty} _{t=0} \\gamma ^{t} r(b_t,\\pi(b_t)) \\middle\\vert b_0=b\\right]$\n","\n","Opening the sum above, on can retrieve the Bellman equation:\n","\n","$V^{\\pi^*}(b)  =  \\max_{a\\in A } \\left[ \\sum_{s\\in S}r(s,a)b(s) + \\gamma\\sum_{o \\in \\Omega} p(o|a,b)V^{\\pi^*}(b^a_o)\\right]$\n","\n","Thus, an optimal policy $\\pi^*$ is defined by $V^{\\pi^*}$ that satisfies this Bellman. The solution is said optimal when $V^*=V^{\\pi^*}$ converges to a fixed point for any $b$. In other words, one could iterate on this value function $\\forall b$ until it converges, and then extract the related policy.\n","\n","However:\n","1. the exact solution in infinite horizon settings is *hard* to compute (PSPACE-complete)\n","2. actually, current algorithms approach the optimal solution, exploiting particular properties: of the value function and of the system dynamics.\n"]},{"cell_type":"markdown","metadata":{"id":"MP9VF_haJvb3"},"source":["#### Value Function parametrization\n","\n","1. The infinite horizon value function $V^{\\pi}(b) = E_{\\pi}\\left[\\sum ^{\\infty} _{t=0} \\gamma ^{t} r(b_t,\\pi(b_t)) \\middle\\vert b_0=b\\right]$ can be approximated by the finite horizon optimal value function $V^{\\pi}(b) = E_{\\pi}\\left[\\sum ^{N} _{t=0} r(b_t,\\pi(b_t)) \\middle\\vert b_0=b\\right]$ which is a piece-wise linear and convex (PWLC) function.\n","\n","2. If the function $F: \\mathbb{R}^{S} \\rightarrow \\mathbb{R}$ is a PWLC function,\n","it exists a finite set of vectors of $\\mathbb{R}^{S}$,\n","denoted by $\\{ \\alpha_i \\}_{i=1}^n$, such that $F$ can be written \n","$F(b) = \\displaystyle \\max_{i=1}^n \\alpha_i \\cdot b = \\max_{i=1}^n \\sum_{s \\in S} \\alpha_{i}(s) \\cdot b(s)$.\n","Since the belief state $b$ is a probability distribution over $S$, \n","we can write $b: S \\rightarrow [0,1]$, and even $b \\in \\mathbb{R}^S$. \n","The approximation of the optimal value function \n","$V: \\mathbb{R}^S \\rightarrow \\mathbb{R}$ \n","can be parameterized by a set of $\\alpha$-vectors\n","$\\Gamma_n = \\left\\lbrace \\alpha_i \\right\\rbrace_{i=1}^n$, with $\\alpha_i \\in \\mathbb{R}^S$, $\\forall i$.\n","Indeed,\n","$V(b) = \\displaystyle \\max_{\\alpha \\in \\Gamma_n} \\alpha \\cdot b = \\max_{\\alpha \\in \\Gamma_n} \\sum_{s \\in S} \\alpha(s) \\cdot b(s)$.\n","$%i \\in 1,...,|V_n|$\n","3. In fact, $V$ is defined on the belief space\n","$\\{ b \\in \\mathbb{R}^S \\mid \\sum_s b(s)=1 \\}$.\n","Each $\\alpha$-vector $\\alpha_i \\in \\mathbb{R}^S$\n","is associated with an action $a(\\alpha) \\in A$,\n","and defines a region of the belief space, \n","where $\\alpha_i \\cdot b = \\max_j \\alpha_j \\cdot b = V(b)$,\n","that is, where $\\alpha_i \\cdot b$ reaches is maximum.\n","The $\\alpha$-vectors form then a partition of the belief state.\n","\n","$$%V_n(b)  =  \\max _{\\alpha ^i_n \\in \\Gamma_n} \\sum _{s \\in S} b(s)\\alpha ^i_n(s) \\rightarrow V_n(b)  =  \\max_{\\alpha ^i_n \\in \\Gamma_n}b\\cdot \\alpha _n^i$$ \n","\n","Thus, for a given belief state $b$, the gradient of the value function is induced by the vector:\n","\n","$$ \\alpha^b = \\operatorname*{arg\\,max}_{\\alpha \\in \\Gamma_n} b \\cdot \\alpha $$\n","\n","and, the associated policy $\\pi(b) \\in A$ is the action of this $\\alpha$-vector, that is: \n","$\\pi(b) = a(\\alpha^b)$. "]},{"cell_type":"markdown","metadata":{"id":"Qzc_1RoAJvb4"},"source":["#### Solving Algorithm : point-based value iteration  (PBVI)\n","\n","#### Value backup operation:\n","Let's define a $V_n$ parameterized by a set $\\Gamma_n$ of $\\alpha$-vectors and a given belief state $b$. One can compute $\\alpha^b_{n+1}$ of $V_{n+1}$ from $LV_n$ (the unknown set of vectors):\n","$\\alpha _{n+1}^b = arg\\max_{\\alpha _{n+1}^i \\in \\mathcal{L}V_n} b \\cdot \\alpha _{n+1}^i,$\n","\n","Let's define $r_a=r(s,a)$ and $b \\cdot r_a = \\sum_s b(s)r(s,a)$, and a set of belief states $\\mathcal B$ where $b\\in \\mathcal B$, we have:\n","$V_{n+1}(b) = \\max _a \\left[ b \\cdot r_a + \\gamma \\sum _o p(o \\mid a,b)V_n(b_o^a) \\right]$\n","\n","$ = \\max _a \\left[ b \\cdot r_a + \\gamma \\sum _o p(o \\mid b,a) \\max _{\\alpha _{n}^i \\in V_n} \\sum _{s'}b_o^a(s')\\alpha _n^i(s')\\right]$\n","\n","$ =  \\max _a \\left[ b \\cdot r_a + \\gamma \\sum _o p(o\\mid b,a) \\max _{\\alpha _{n}^i \\in V_n} \\frac {\\sum _{s'} p(o \\mid s',a) \\sum _s p(s' \\mid s,a)b(s)\\alpha _n^i(s')}{p(o\\mid b,a)}\\right]$\n","\n","$ =  \\max _a \\left[ b \\cdot r_a + \\gamma \\sum _o \\max _{\\alpha _{n}^i \\in V_n} \\sum _s \\sum _{s'} p(o \\mid s',a) p(s' \\mid s,a)b(s)\\alpha _n^i(s')\\right]$\n","\n","thus: $ V_{n+1}(b)  =  \\max _a \\left[ b \\cdot r_a + \\gamma \\sum _o \\max _{\\alpha^{a,o}_i \\in \\Gamma^{a,o}} b \\cdot \\alpha^{a,o}_i \\right] $\n","\n","Then, applying $\\max _j b \\cdot \\alpha _j = b \\cdot \\operatorname*{arg\\,max}_j b\\cdot \\alpha_j$ two times, we have:\n","\n","$backup(b)  =  arg\\max_{\\alpha^{a}_b \\in \\Gamma^a_b} b \\cdot \\alpha^a_b$\n","\n","$\\mathrm{with} \\; \\Gamma^a_b  \\leftarrow  r_a + \\gamma \\sum _o arg\\max_{\\alpha^{a,o}_i \\in \\Gamma^{a,o}} b \\cdot \\alpha^{a,o}_i$\n","\n","#### Algorithm\n","\n","<img src=\"../figures/pbvi.png\" width=\"600\">\n","\n","The output of this algorithm is a set of $\\alpha$-vectors $\\Gamma$ approximating the value function. Each $\\alpha$-vector has an associated action $a$.\n","\n","At execution time, one can determine the best action for a given belief state $b$, appying:\n","\n","$$ \\alpha^b = \\operatorname*{arg\\,max}_{\\alpha \\in \\Gamma} b \\cdot \\alpha $$\n","\n","and, the associated policy $\\pi(b) \\in A$ is the action of this $\\alpha$-vector, that is $\\pi(b) = a(\\alpha^b)$. \n","\n","#### Provided library\n","The PyPOMDP library (see https://github.com/namoshizun/PyPOMDP) is provided with this notebook. \n","\n","This library proposes two state-of-the-art algorithms, PBVI and POMCP (do not hesitate to get a look in the Caroline's slides courses). However, this library has been customized with several additional features that will be very useful for this practical work.\n","\n","For instance, the library now save a Value Function parametrized by $\\alpha$-vectors, in a file. This can be then reloaded to simulate the policy in order to evaluate futur gains, or in order to replay an experiment.\n","\n","In this practical work course we will mainly use the implementation of PBVI."]},{"cell_type":"markdown","metadata":{"id":"IBqEJ72WJvb4"},"source":["# THE FIREFIGTHER ROBOT GAME\n","\n","## Experiments conduted in the lab\n","During lab experiments, 18 volunteers equipped with physiological sensors have played the Firefigther Robot Game.\n","http://robot-isae.isae.fr\n","\n","![sujet.JPG](attachment:sujet.JPG)\n","\n","Each participant followed an experimental protocol in which 4 missions are played. Please see the FireFigther game presentation for more details.\n","\n","![procedureEnglish.png](attachment:procedureEnglish.png)\n"]},{"cell_type":"markdown","metadata":{"id":"Trrhc66yJvb4"},"source":["## Mission scoring \n","\n","The number of extinguished fires allowed to quantify how well a mission has been performed. We could define two performance group using the median score as a threshold to obtain a balanced dataset. Each mission was then labeled as: 0 for low scoring mission group (low performance); and 1 for high scoring mission group (high performance).\n","\n","\n","## Datasets\n","\n","Two datasets are provided:\n","1. A labeled dataFrame including preprocessed markers for each 10-second time window, mission and participant\n","2. A labeled dataFrame gathering **averaged markers** results for each 10-second time window, mission, participant and robot operation mode\n"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"aEKOwLipJvb5","outputId":"719a33f7-b00c-4567-faa5-736cd21dad07"},"outputs":[{"name":"stdout","output_type":"stream","text":["      subject  mission  mode         HR       HRV   nav  tank  space  trees  \\\n","0        19.0      1.0   0.0  72.568940 -0.066819  14.0   0.0    0.0    0.0   \n","1        19.0      1.0   0.0  74.229865 -0.087446  18.0   2.0    0.0    0.0   \n","2        19.0      1.0   1.0  73.304826 -0.070724   9.0   5.0    0.0    0.0   \n","3        19.0      1.0   1.0  69.962687 -0.050697   0.0   8.0    0.0    0.0   \n","4        19.0      1.0   1.0  70.771408 -0.076950   0.0   7.0    0.0    1.0   \n","...       ...      ...   ...        ...       ...   ...   ...    ...    ...   \n","3586     40.0      4.0   1.0  69.767442 -0.041904   0.0  24.0    0.0    0.0   \n","3587     40.0      4.0   0.0  67.046597 -0.043276  12.0   8.0    0.0    0.0   \n","3588     40.0      4.0   0.0  69.549090 -0.044936  10.0  14.0    0.0    0.0   \n","3589     40.0      4.0   0.0  72.245635 -0.045260   6.0   8.0    1.0    0.0   \n","3590     40.0      4.0   1.0  71.564885 -0.048838   2.0   9.0    0.0    0.0   \n","\n","      nbAOI1  ...  nbAOI4  nbAOI5  durAOI1   durAOI2  durAOI3   durAOI4  \\\n","0        0.0  ...    17.0    13.0      0.0     0.000  396.012  4315.727   \n","1        0.0  ...    14.0     8.0      0.0   799.830  616.039  5164.160   \n","2        0.0  ...     6.0     2.0      0.0  4567.621  323.665  1076.000   \n","3        0.0  ...     2.0     0.0      0.0  8334.850  507.983   404.020   \n","4        0.0  ...     0.0     4.0      0.0  6839.057  288.020     0.000   \n","...      ...  ...     ...     ...      ...       ...      ...       ...   \n","3586     0.0  ...     5.0     2.0      0.0  8130.931    0.000   843.695   \n","3587     0.0  ...    10.0     3.0      0.0  3607.340    0.000  3371.289   \n","3588     0.0  ...    15.0     1.0      0.0  4155.458    0.000  4095.549   \n","3589     0.0  ...     7.0     2.0      0.0  4499.490    0.000  4619.240   \n","3590     0.0  ...    12.0     7.0      0.0  3847.525    0.000  3134.870   \n","\n","       durAOI5  tank_local_score    HRnorm  label  \n","0     2627.351             0.000  6.185203    1.0  \n","1     1296.772            -2.222  7.846128    1.0  \n","2      411.970            -8.445  6.921088    1.0  \n","3        0.000             4.555  3.578949    1.0  \n","4     1471.901            19.032  4.387671    1.0  \n","...        ...               ...       ...    ...  \n","3586   339.979             7.286  3.992174    0.0  \n","3587  1307.800             2.714  1.271330    0.0  \n","3588   156.010             3.778  3.773822    0.0  \n","3589   415.880            -0.334  6.470367    0.0  \n","3590  1252.000            -1.111  5.789618    0.0  \n","\n","[3591 rows x 22 columns]\n","            HR       HRV     HRnorm    durAOI1      durAOI2      durAOI3  \\\n","0    73.305546 -0.069436   6.921808   4.932333  2129.406367  2678.168567   \n","1    72.956445 -0.063483   6.572708   0.000000  6571.811483   566.278000   \n","2    71.576225 -0.091708   8.067361  12.141286  1797.237214  3547.153714   \n","3    72.168841 -0.090276   8.659977   4.741111  6226.135370   668.982037   \n","4    73.885036 -0.096448  10.241172   0.000000  1606.564280  3391.440920   \n","..         ...       ...        ...        ...          ...          ...   \n","139  66.093630 -0.043516   0.539398   0.000000  5223.128500     0.000000   \n","140  67.925163 -0.044169   0.990982   0.000000  4067.073143    48.568571   \n","141  69.152892 -0.038705   2.218711   0.000000  4967.913200    64.788000   \n","142  68.981841 -0.040580   3.206573   0.000000  3645.349444   131.996111   \n","143  69.233786 -0.042072   3.458518   0.000000  5313.447909   108.345455   \n","\n","         durAOI4      durAOI5  mission  mode  ...     nbAOI3     nbAOI4  \\\n","0    1783.765767   975.935567        1     0  ...  13.333333   7.400000   \n","1     518.711793   577.381034        1     1  ...   2.517241   2.172414   \n","2    1615.460000  1010.015536        2     0  ...  16.321429   6.250000   \n","3     312.901556   696.532074        2     1  ...   2.925926   1.259259   \n","4    1552.987520   908.531080        3     0  ...  17.440000   6.800000   \n","..           ...          ...      ...   ...  ...        ...        ...   \n","139  3197.380500   279.983500        2     1  ...   0.000000  10.000000   \n","140  4125.931286   588.783929        3     0  ...   0.285714  12.571429   \n","141  2969.286400   544.709600        3     1  ...   0.400000  10.000000   \n","142  3920.527611   654.800944        4     0  ...   0.611111  13.166667   \n","143  2471.960409   938.529909        4     1  ...   0.636364   9.954545   \n","\n","       nbAOI5     space  subject       tank  tank_local_score     trees  \\\n","0    5.166667  0.533333       19   2.233333         -3.089643  0.466667   \n","1    2.965517  0.206897       19   6.206897          3.802909  0.379310   \n","2    5.392857  0.500000       19   1.857143         -6.680850  0.428571   \n","3    3.629630  0.222222       19   7.111111          4.718641  0.481481   \n","4    5.200000  0.720000       19   1.200000         -8.362847  0.720000   \n","..        ...       ...      ...        ...               ...       ...   \n","139  1.500000  0.000000       40   9.000000         -2.833000  0.500000   \n","140  2.928571  0.214286       40   8.214286         -1.595214  0.071429   \n","141  3.200000  0.000000       40  10.400000         -0.999800  0.200000   \n","142  3.500000  0.055556       40   7.944444         -3.281372  0.000000   \n","143  5.136364  0.000000       40  14.090909          1.201314  0.363636   \n","\n","     nbt_trees_mode  label  \n","0                14      1  \n","1                11      1  \n","2                12      1  \n","3                13      1  \n","4                18      1  \n","..              ...    ...  \n","139               1      0  \n","140               1      0  \n","141               1      0  \n","142               0      0  \n","143               8      0  \n","\n","[144 rows x 23 columns]\n"]}],"source":["import pandas as pd\n","import numpy as np\n","\n","# example :\n","# importing label dataset including preprocessed markers for each 10-second time window, mission and participant\n","# this dataset will be useful for classification purposes\n","df10labeled_data = pd.read_csv('./data/df10labeled_data.csv')\n","print(df10labeled_data)\n","\n","# example:\n","# importing labeled dataset with averaged or summed markers results for each \n","# 10-second time window, mission, participant and robot operation mode\n","averagedPMPVmode_w10_data = pd.read_csv('./data/averagedPMPVmode_w10_data.csv')\n","print(averagedPMPVmode_w10_data)\n"]},{"cell_type":"markdown","metadata":{"id":"ZN_u9yJfJvb6"},"source":["### Markers description\n","* **subject** : identification number of the participant\n","* **mission** : identification number of the mission (1, 2, 3 or 4)\n","* **mode** : robot operation mode (0 for manual, 1 for autonomous)\n","* **HR** : average of the participant's heart-rate (on the 10sec window) \n","* **normHR** : normalized participant's heart-rate (w.r.t. the rest period)\n","* **HRV** : normalized heart-rate variability (w.r.t. the rest period)\n","* **nav** : total number of keystrokes and cliks related with robot navigation control task in the 10sec window.\n","* **tank** : total number of  keystrokes/clicks realted with the external tank management task in the 10sec window.\n","* **space** : total number of times the space key was pressed in the 10sec window.\n","* **trees** : total number of trees on fire that are extinghised using the space keyboard in the 10sec window.\n","* **nbAOI1** : total number of eye fixations in the AOI (Areas-Of-Interest) number 1 (same for the others).\n","* **durAOI1** : total duration of fixations performed in the AOI number 1 (same for the others)\n","* **tank_local_score** : how much the external tank level has increased/decreased in the last 10s.\n","* **nbt_trees_mode** : total number of extinguished trees per operation mode\n","* **label**: {0,1} boolean indicating if the final mission score is good (1) or bad (0). Note that in this work we will consider that it reflects the mental state of the human operator: 1 for $e$ (engaged / performant) and 0 for $ne$ (not engaged / not performant)."]},{"cell_type":"markdown","metadata":{"id":"4FbjrzD_Jvb6"},"source":["# PRACTICAL WORK TASKS"]},{"cell_type":"markdown","metadata":{"id":"jxd4mRJaJvb6"},"source":["## Task 1 : Defining the POMDP model "]},{"cell_type":"markdown","metadata":{"id":"2hgvsETSJvb6"},"source":["As our goal is to drive (i.e. control) the interaction between the human operator and the robot in function of the human operator engagement (cf. presentation):\n","\n","1. We define the state space as $S = S_h$, where $S_h = \\{e, ne\\}$, to express the human partially observable mental state of (a correct) engagement ($e$) or the absence of (a correct) engagement ($ne$). Note that this last mental state encapsulates disengaged and over-engaged cases, in which participants performed badly.\n","2. We define the action space as $A = \\{manual, auto\\}$, representing the possible decisions of our POMDP agent about which robot operation mode (manual or autonomous mode) should be used.\n","3. We define the observation space as $\\Omega =  \\{oe, one\\}$, that are the possible predictions of a classifier trained to detect human engagement based on available behavioral and physiological data.\n","\n","The transition function is defined as $p(s, a, s') = Pr(s' \\mid s,a) = \\left \\{ \\begin{array}{cc} 1 - \\epsilon & \\mbox{if } s=s'\\\\ \\epsilon & \\mbox{ otherwise } \\end{array} \\right.$. Note that the dynamics of the operator engagement in the task is rougly approached using the fact that an \"engaged\" human operator remains \"engaged\" with a small probability ($\\epsilon$) for changing its mental state to \"not engaged\".\n","\n","**It will be your job to define of the observation $o()$ and the reward $r()$ functions. For that, you may make use of the provided behavioral and physiological data.**\n","\n","We notice that the time step $t$ in our POMDP model refers to a 10-second time window. In other words, the POMDP agent plays an action every 10s."]},{"cell_type":"markdown","metadata":{"id":"8s5ZyzwaJvb6"},"source":["### Task 1.1 : Define the POMDP observation function\n","\n","To achieve this step, proceed by chosing features and use them to train and test a classifier. \n","\n","The output of this classifier will be the prediction (observation) about the human operator engagement based on data. As explained, ET, ECG and HAI markers are provided. **It is your job to choose which markers are relevant to be used as features.**\n","\n","In order to check on markers relevance, we suggest you perform decriptive and statistical analysis."]},{"cell_type":"markdown","metadata":{"id":"hXKUh7-wJvb7"},"source":["#### Task 1.1.1: Descriptive data analysis"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"YOR8M_JvJvb7","executionInfo":{"status":"error","timestamp":1645086085590,"user_tz":-60,"elapsed":1080,"user":{"displayName":"Quentin Bernaudon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08827465376849456822"}},"outputId":"2d56d5cc-b62a-479b-815f-cbd894ac42ca","colab":{"base_uri":"https://localhost:8080/","height":396}},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-a968fc2ec730>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m#######################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# importing data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mdfaveraged_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/averagedPMPVmode_w10_data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m## Plotting display examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/averagedPMPVmode_w10_data.csv'"]}],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as mpatches\n","import seaborn as sns\n","\n","######################################################################\n","### Defining some useful plotting function for you\n","def plotting_data_per_mode(data, xstr, ystr):\n","    palette=sorted(sns.color_palette(\"BuGn\", 10), reverse=True)\n","    palette = [palette[6], palette[9]]\n","    sns.set_context(\"paper\", font_scale=1, rc={\"lines.linewidth\": 2.5})\n","    sns.boxenplot(x=xstr, y=ystr, hue=\"mode\", palette=palette, linewidth=1, data=dfaveraged_data)\n","    #plt.ylim([-1, 30])\n","    plt.xticks([0, 1], ['low scores group', 'high scores group'])\n","    sns.despine(offset=10, trim=True)\n","    plt.legend(loc='best')\n","    \n","def plotting_data_per_perfgroup(data, xstr, ystr):\n","    palette=sorted(sns.color_palette(\"BuGn\", 10), reverse=True)\n","    palette = [palette[6], palette[9]]\n","    sns.set_context(\"paper\", font_scale=1, rc={\"lines.linewidth\": 2.5})\n","    #sns.boxenplot(x=xstr, y=ystr, hue=\"label\", palette=palette, linewidth=1, data=dfaveraged_data)\n","    sns.boxenplot(x=xstr, y=ystr, hue=\"label\", linewidth=1, data=dfaveraged_data)\n","    #plt.ylim([-1, 30])\n","    plt.xticks([0, 1], ['manual', 'auto'])\n","    sns.despine(offset=10, trim=True)\n","    plt.legend(loc='best')\n","    plt.show()\n","    \n","\n","#######################################################################\n","# importing data\n","dfaveraged_data = pd.read_csv('./data/averagedPMPVmode_w10_data.csv')\n","\n","## Plotting display examples\n","## Note these plots represent quantiles of the quantitative variables\n","## plotting operation mode x HRnorm grouped by the performance label\n","plotting_data_per_perfgroup(dfaveraged_data, \"mode\", \"HRnorm\")\n","plt.show()\n","#plt.clf()\n","\n","## plotting operation mode x HRV grouped by the performance label\n","plotting_data_per_perfgroup(dfaveraged_data, \"mode\", \"HRV\")\n","plt.show()\n","#plt.clf()\n","\n","## plotting operation mode x nav keystrokes grouped by the performance label\n","plotting_data_per_perfgroup(dfaveraged_data, \"mode\", \"nav\")\n","plt.show()\n","#plt.clf()\n","\n","## plotting operation mode x nbAOI2 keystrokes grouped by the performance label\n","plotting_data_per_perfgroup(dfaveraged_data, \"mode\", \"nbAOI2\")\n","plt.show()\n","#plt.clf()\n","\n","\n","### PLEASE CONTINUE DESCRIPTIVE STATISTICAL ANALYSIS\n","## use summary statistics from scipy.stats library  \n","\n","## plotting operation mode x nbAOI1 keystrokes grouped by the performance label\n","plotting_data_per_perfgroup(dfaveraged_data, \"mode\", \"nbAOI1\")\n","plt.show()\n","#plt.clf()\n","\n","## plotting operation mode x nbAOI3 keystrokes grouped by the performance label\n","plotting_data_per_perfgroup(dfaveraged_data, \"mode\", \"nbAOI3\")\n","plt.show()\n","#plt.clf()\n"," \n","## plotting operation mode x nbAOI4 keystrokes grouped by the performance label\n","plotting_data_per_perfgroup(dfaveraged_data, \"mode\", \"nbAOI4\")\n","plt.show()\n","#plt.clf()   \n","\n","## plotting operation mode x nbAOI5 keystrokes grouped by the performance label\n","plotting_data_per_perfgroup(dfaveraged_data, \"mode\", \"nbAOI5\")\n","plt.show()\n","#plt.clf()\n","\n","\n","## plotting operation mode x tank keystrokes grouped by the performance label\n","plotting_data_per_perfgroup(dfaveraged_data, \"mode\", \"tank\")\n","plt.show()\n","#plt.clf()\n","\n","                                     \n"]},{"cell_type":"markdown","metadata":{"id":"GRvBGwClJvb7"},"source":["#### Draw conclusions for task 1.1.1 here:\n"]},{"cell_type":"markdown","metadata":{"id":"4cHJRFt3Jvb7"},"source":["Answer: Les marqueurs les plus pertinents pour entrainer notre classifieur sont ceux qui présentent des valeurs significativement différentes entre les groupes de bonnes performances et de basses performances.\n","Concernant l'impact du mode de jeu (manuel ou auto), son importance est moindre car la performance globale du joueur est reflétée en mode manuel.\n","Par conséquent, au vu des médianes et des écarts types obtenus pour chaque marqueur moyenné, nous choisissons dans un premier temps les marqueurs nav, nbAOI1, nbAOI3 et nbAOI5."]},{"cell_type":"markdown","metadata":{"id":"_z3jiSwGJvb7"},"source":["**Task 1.1.2: Statistical analysis**\n","\n","To achieve this task, get a look on the data, and answer the following questions\n","* **Which are the markers significantly impacted by the human operator perf/engagement (POMDP observation)?**\n","* **Are the markers also impacted by the robot operation mode (POMDP action)?**\n","\n","**For that, you have to formally define the null hypothesis (H0) and the alternative one (H1) for each statistical test**\n","\n","**Remark 1 :** make use of ***Introduction to Statistics for Experimentations*** course (DNIA302) to achieve this step.\n","\n","**Remark 2 :** note that the **averaged data file (averagedPMPVmode_w10_data) will be used for this analysis**. The 10-second time window data is averaged by participant, mission and operation mode. Additional columns appear, providing the total number of trees extinguished for each operation mode, as well as the performance/engagement label."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Crr6XAjlJvb8","outputId":"8e6f93c2-fb94-49e4-c3f1-ff9769c4e73c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Index(['HR', 'HRV', 'HRnorm', 'durAOI1', 'durAOI2', 'durAOI3', 'durAOI4',\n","       'durAOI5', 'mission', 'mode', 'nav', 'nbAOI1', 'nbAOI2', 'nbAOI3',\n","       'nbAOI4', 'nbAOI5', 'space', 'subject', 'tank', 'tank_local_score',\n","       'trees', 'nbt_trees_mode', 'label', 'modeperf', 'submission'],\n","      dtype='object')\n","#####################################################################\n","2-WAY ANOVA H1: HRV is impacted by the operation mode and the performance (label)\n","Overall model F( 3, 140) =  5.830, p =  0.0009\n","\n","                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:                    HRV   R-squared:                       0.111\n","Model:                            OLS   Adj. R-squared:                  0.092\n","Method:                 Least Squares   F-statistic:                     5.830\n","Date:                Thu, 11 Mar 2021   Prob (F-statistic):           0.000879\n","Time:                        10:34:30   Log-Likelihood:                 325.64\n","No. Observations:                 144   AIC:                            -643.3\n","Df Residuals:                     140   BIC:                            -631.4\n","Df Model:                           3                                         \n","Covariance Type:            nonrobust                                         \n","==============================================================================================\n","                                 coef    std err          t      P>|t|      [0.025      0.975]\n","----------------------------------------------------------------------------------------------\n","Intercept                     -0.0273      0.004     -6.403      0.000      -0.036      -0.019\n","C(mode)[T.1]                   0.0006      0.006      0.092      0.927      -0.011       0.012\n","C(label)[T.1]                 -0.0182      0.006     -3.026      0.003      -0.030      -0.006\n","C(mode)[T.1]:C(label)[T.1]     0.0009      0.009      0.105      0.916      -0.016       0.018\n","==============================================================================\n","Omnibus:                       24.567   Durbin-Watson:                   0.576\n","Prob(Omnibus):                  0.000   Jarque-Bera (JB):               33.473\n","Skew:                          -0.945   Prob(JB):                     5.39e-08\n","Kurtosis:                       4.416   Cond. No.                         6.85\n","==============================================================================\n","\n","Warnings:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","\n","                    sum_sq     df          F    PR(>F)\n","C(mode)           0.000036    1.0   0.055611  0.813917\n","C(label)          0.011394    1.0  17.423777  0.000052\n","C(mode):C(label)  0.000007    1.0   0.011104  0.916230\n","Residual          0.091551  140.0        NaN       NaN\n","Multiple Comparison of Means - Tukey HSD, FWER=0.05 \n","====================================================\n","group1 group2 meandiff p-adj   lower   upper  reject\n","----------------------------------------------------\n","    00     01  -0.0182 0.0154 -0.0339 -0.0026   True\n","    00     10   0.0006    0.9 -0.0151  0.0162  False\n","    00     11  -0.0168 0.0307 -0.0325 -0.0011   True\n","    01     10   0.0188 0.0117  0.0031  0.0345   True\n","    01     11   0.0015    0.9 -0.0142  0.0171  False\n","    10     11  -0.0173 0.0237  -0.033 -0.0017   True\n","----------------------------------------------------\n","#####################################################################\n","2-WAY ANOVA H1: HR is impacted by the operation mode and the performance (label)\n","Overall model F( 3, 140) =  0.165, p =  0.9195\n","\n","                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:                     HR   R-squared:                       0.004\n","Model:                            OLS   Adj. R-squared:                 -0.018\n","Method:                 Least Squares   F-statistic:                    0.1655\n","Date:                Thu, 11 Mar 2021   Prob (F-statistic):              0.919\n","Time:                        10:34:30   Log-Likelihood:                -524.93\n","No. Observations:                 144   AIC:                             1058.\n","Df Residuals:                     140   BIC:                             1070.\n","Df Model:                           3                                         \n","Covariance Type:            nonrobust                                         \n","==============================================================================================\n","                                 coef    std err          t      P>|t|      [0.025      0.975]\n","----------------------------------------------------------------------------------------------\n","Intercept                     76.9093      1.566     49.103      0.000      73.813      80.006\n","C(mode)[T.1]                   0.1709      2.215      0.077      0.939      -4.208       4.550\n","C(label)[T.1]                  1.2235      2.215      0.552      0.582      -3.156       5.603\n","C(mode)[T.1]:C(label)[T.1]    -0.2562      3.133     -0.082      0.935      -6.450       5.937\n","==============================================================================\n","Omnibus:                        9.107   Durbin-Watson:                   0.317\n","Prob(Omnibus):                  0.011   Jarque-Bera (JB):                6.386\n","Skew:                           0.385   Prob(JB):                       0.0410\n","Kurtosis:                       2.314   Cond. No.                         6.85\n","==============================================================================\n","\n","Warnings:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","\n","                        sum_sq     df         F    PR(>F)\n","C(mode)               0.065951    1.0  0.000747  0.978238\n","C(label)             43.191478    1.0  0.489041  0.485516\n","C(mode):C(label)      0.590959    1.0  0.006691  0.934923\n","Residual          12364.626317  140.0       NaN       NaN\n","Multiple Comparison of Means - Tukey HSD, FWER=0.05\n","==================================================\n","group1 group2 meandiff p-adj  lower  upper  reject\n","--------------------------------------------------\n","    00     01   1.2235   0.9 -4.5365 6.9834  False\n","    00     10   0.1709   0.9  -5.589 5.9309  False\n","    00     11   1.1381   0.9 -4.6218 6.8981  False\n","    01     10  -1.0525   0.9 -6.8125 4.7074  False\n","    01     11  -0.0853   0.9 -5.8453 5.6746  False\n","    10     11   0.9672   0.9 -4.7927 6.7272  False\n","--------------------------------------------------\n","                 Anova\n","========================================\n","         F Value  Num DF  Den DF  Pr > F\n","----------------------------------------\n","AOI      458.5680 4.0000 284.0000 0.0000\n","mode      49.1675 1.0000  71.0000 0.0000\n","AOI:mode 281.0315 4.0000 284.0000 0.0000\n","========================================\n","\n","#####################################################################\n","3-WAY ANOVA H1: nbFix is impacted by the AOI, the operation mode and the performance (label)\n","                              sum_sq     df           F        PR(>F)\n","Intercept                   0.749868    1.0    0.111368  7.386915e-01\n","C(mode)                     0.095561    1.0    0.014192  9.052048e-01\n","C(label)                    2.480939    1.0    0.368463  5.440402e-01\n","C(AOI)                   3392.106984    4.0  125.946805  5.762745e-81\n","C(mode):C(label)            0.003842    1.0    0.000571  9.809498e-01\n","C(mode):C(AOI)           1197.868912    4.0   44.476122  2.720559e-33\n","C(label):C(AOI)           467.112575    4.0   17.343597  1.408599e-13\n","C(mode):C(label):C(AOI)   270.317684    4.0   10.036726  6.664011e-08\n","Residual                 4713.249547  700.0         NaN           NaN\n","     Multiple Comparison of Means - Tukey HSD, FWER=0.05      \n","==============================================================\n","  group1     group2   meandiff p-adj   lower    upper   reject\n","--------------------------------------------------------------\n","0_0_nbAOI1 0_0_nbAOI2  12.3829  0.001  10.2069  14.5589   True\n","0_0_nbAOI1 0_0_nbAOI3   8.5979  0.001   6.4219  10.7739   True\n","0_0_nbAOI1 0_0_nbAOI4   6.2206  0.001   4.0446   8.3966   True\n","0_0_nbAOI1 0_0_nbAOI5   2.7309 0.0016   0.5549   4.9069   True\n","0_0_nbAOI1 0_1_nbAOI1   0.3713    0.9  -1.8047   2.5472  False\n","0_0_nbAOI1 0_1_nbAOI2  11.5057  0.001   9.3297  13.6817   True\n","0_0_nbAOI1 0_1_nbAOI3  14.2422  0.001  12.0662  16.4182   True\n","0_0_nbAOI1 0_1_nbAOI4   6.3071  0.001   4.1312   8.4831   True\n","0_0_nbAOI1 0_1_nbAOI5   3.9788  0.001   1.8028   6.1548   True\n","0_0_nbAOI1 1_0_nbAOI1   0.0729    0.9  -2.1031   2.2488  False\n","0_0_nbAOI1 1_0_nbAOI2   18.463  0.001   16.287  20.6389   True\n","0_0_nbAOI1 1_0_nbAOI3   3.6173  0.001   1.4413   5.7933   True\n","0_0_nbAOI1 1_0_nbAOI4   3.9715  0.001   1.7955   6.1475   True\n","0_0_nbAOI1 1_0_nbAOI5   2.4909  0.008   0.3149   4.6669   True\n","0_0_nbAOI1 1_1_nbAOI1   0.4648    0.9  -1.7112   2.6407  False\n","0_0_nbAOI1 1_1_nbAOI2  20.8697  0.001  18.6937  23.0457   True\n","0_0_nbAOI1 1_1_nbAOI3   4.8422  0.001   2.6663   7.0182   True\n","0_0_nbAOI1 1_1_nbAOI4    3.615  0.001    1.439   5.7909   True\n","0_0_nbAOI1 1_1_nbAOI5   3.7529  0.001    1.577   5.9289   True\n","0_0_nbAOI2 0_0_nbAOI3   -3.785  0.001   -5.961   -1.609   True\n","0_0_nbAOI2 0_0_nbAOI4  -6.1623  0.001  -8.3383  -3.9863   True\n","0_0_nbAOI2 0_0_nbAOI5   -9.652  0.001  -11.828   -7.476   True\n","0_0_nbAOI2 0_1_nbAOI1 -12.0116  0.001 -14.1876  -9.8357   True\n","0_0_nbAOI2 0_1_nbAOI2  -0.8772    0.9  -3.0532   1.2988  False\n","0_0_nbAOI2 0_1_nbAOI3   1.8593 0.2139  -0.3167   4.0353  False\n","0_0_nbAOI2 0_1_nbAOI4  -6.0758  0.001  -8.2517  -3.8998   True\n","0_0_nbAOI2 0_1_nbAOI5  -8.4041  0.001 -10.5801  -6.2281   True\n","0_0_nbAOI2 1_0_nbAOI1   -12.31  0.001  -14.486 -10.1341   True\n","0_0_nbAOI2 1_0_nbAOI2   6.0801  0.001   3.9041    8.256   True\n","0_0_nbAOI2 1_0_nbAOI3  -8.7656  0.001 -10.9415  -6.5896   True\n","0_0_nbAOI2 1_0_nbAOI4  -8.4114  0.001 -10.5874  -6.2354   True\n","0_0_nbAOI2 1_0_nbAOI5   -9.892  0.001 -12.0679   -7.716   True\n","0_0_nbAOI2 1_1_nbAOI1 -11.9181  0.001 -14.0941  -9.7421   True\n","0_0_nbAOI2 1_1_nbAOI2   8.4868  0.001   6.3108  10.6628   True\n","0_0_nbAOI2 1_1_nbAOI3  -7.5406  0.001  -9.7166  -5.3647   True\n","0_0_nbAOI2 1_1_nbAOI4  -8.7679  0.001 -10.9439   -6.592   True\n","0_0_nbAOI2 1_1_nbAOI5    -8.63  0.001 -10.8059   -6.454   True\n","0_0_nbAOI3 0_0_nbAOI4  -2.3773 0.0161  -4.5533  -0.2013   True\n","0_0_nbAOI3 0_0_nbAOI5   -5.867  0.001   -8.043   -3.691   True\n","0_0_nbAOI3 0_1_nbAOI1  -8.2267  0.001 -10.4026  -6.0507   True\n","0_0_nbAOI3 0_1_nbAOI2   2.9078  0.001   0.7318   5.0837   True\n","0_0_nbAOI3 0_1_nbAOI3   5.6443  0.001   3.4683   7.8203   True\n","0_0_nbAOI3 0_1_nbAOI4  -2.2908 0.0267  -4.4668  -0.1148   True\n","0_0_nbAOI3 0_1_nbAOI5  -4.6191  0.001  -6.7951  -2.4431   True\n","0_0_nbAOI3 1_0_nbAOI1   -8.525  0.001  -10.701  -6.3491   True\n","0_0_nbAOI3 1_0_nbAOI2   9.8651  0.001   7.6891   12.041   True\n","0_0_nbAOI3 1_0_nbAOI3  -4.9806  0.001  -7.1566  -2.8046   True\n","0_0_nbAOI3 1_0_nbAOI4  -4.6264  0.001  -6.8024  -2.4505   True\n","0_0_nbAOI3 1_0_nbAOI5   -6.107  0.001   -8.283   -3.931   True\n","0_0_nbAOI3 1_1_nbAOI1  -8.1331  0.001 -10.3091  -5.9572   True\n","0_0_nbAOI3 1_1_nbAOI2  12.2718  0.001  10.0958  14.4478   True\n","0_0_nbAOI3 1_1_nbAOI3  -3.7557  0.001  -5.9316  -1.5797   True\n","0_0_nbAOI3 1_1_nbAOI4   -4.983  0.001  -7.1589   -2.807   True\n","0_0_nbAOI3 1_1_nbAOI5   -4.845  0.001   -7.021   -2.669   True\n","0_0_nbAOI4 0_0_nbAOI5  -3.4897  0.001  -5.6657  -1.3137   True\n","0_0_nbAOI4 0_1_nbAOI1  -5.8494  0.001  -8.0253  -3.6734   True\n","0_0_nbAOI4 0_1_nbAOI2   5.2851  0.001   3.1091    7.461   True\n","0_0_nbAOI4 0_1_nbAOI3   8.0216  0.001   5.8456  10.1976   True\n","0_0_nbAOI4 0_1_nbAOI4   0.0865    0.9  -2.0895   2.2625  False\n","0_0_nbAOI4 0_1_nbAOI5  -2.2418 0.0352  -4.4178  -0.0658   True\n","0_0_nbAOI4 1_0_nbAOI1  -6.1477  0.001  -8.3237  -3.9718   True\n","0_0_nbAOI4 1_0_nbAOI2  12.2424  0.001  10.0664  14.4183   True\n","0_0_nbAOI4 1_0_nbAOI3  -2.6033 0.0038  -4.7793  -0.4273   True\n","0_0_nbAOI4 1_0_nbAOI4  -2.2491 0.0338  -4.4251  -0.0731   True\n","0_0_nbAOI4 1_0_nbAOI5  -3.7297  0.001  -5.9057  -1.5537   True\n","0_0_nbAOI4 1_1_nbAOI1  -5.7558  0.001  -7.9318  -3.5799   True\n","0_0_nbAOI4 1_1_nbAOI2  14.6491  0.001  12.4731  16.8251   True\n","0_0_nbAOI4 1_1_nbAOI3  -1.3784 0.7326  -3.5543   0.7976  False\n","0_0_nbAOI4 1_1_nbAOI4  -2.6057 0.0037  -4.7816  -0.4297   True\n","0_0_nbAOI4 1_1_nbAOI5  -2.4677 0.0092  -4.6437  -0.2917   True\n","0_0_nbAOI5 0_1_nbAOI1  -2.3596 0.0179  -4.5356  -0.1837   True\n","0_0_nbAOI5 0_1_nbAOI2   8.7748  0.001   6.5988  10.9508   True\n","0_0_nbAOI5 0_1_nbAOI3  11.5113  0.001   9.3353  13.6873   True\n","0_0_nbAOI5 0_1_nbAOI4   3.5762  0.001   1.4003   5.7522   True\n","0_0_nbAOI5 0_1_nbAOI5   1.2479 0.8724  -0.9281   3.4239  False\n","0_0_nbAOI5 1_0_nbAOI1   -2.658 0.0026   -4.834  -0.4821   True\n","0_0_nbAOI5 1_0_nbAOI2  15.7321  0.001  13.5561   17.908   True\n","0_0_nbAOI5 1_0_nbAOI3   0.8864    0.9  -1.2896   3.0624  False\n","0_0_nbAOI5 1_0_nbAOI4   1.2406 0.8802  -0.9354   3.4166  False\n","0_0_nbAOI5 1_0_nbAOI5    -0.24    0.9   -2.416    1.936  False\n","0_0_nbAOI5 1_1_nbAOI1  -2.2661 0.0307  -4.4421  -0.0902   True\n","0_0_nbAOI5 1_1_nbAOI2  18.1388  0.001  15.9628  20.3148   True\n","0_0_nbAOI5 1_1_nbAOI3   2.1113 0.0701  -0.0646   4.2873  False\n","0_0_nbAOI5 1_1_nbAOI4   0.8841    0.9  -1.2919     3.06  False\n","0_0_nbAOI5 1_1_nbAOI5    1.022    0.9  -1.1539    3.198  False\n","0_1_nbAOI1 0_1_nbAOI2  11.1344  0.001   8.9585  13.3104   True\n","0_1_nbAOI1 0_1_nbAOI3  13.8709  0.001   11.695  16.0469   True\n","0_1_nbAOI1 0_1_nbAOI4   5.9359  0.001   3.7599   8.1118   True\n","0_1_nbAOI1 0_1_nbAOI5   3.6075  0.001   1.4316   5.7835   True\n","0_1_nbAOI1 1_0_nbAOI1  -0.2984    0.9  -2.4744   1.8776  False\n","0_1_nbAOI1 1_0_nbAOI2  18.0917  0.001  15.9157  20.2677   True\n","0_1_nbAOI1 1_0_nbAOI3   3.2461  0.001   1.0701    5.422   True\n","0_1_nbAOI1 1_0_nbAOI4   3.6002  0.001   1.4243   5.7762   True\n","0_1_nbAOI1 1_0_nbAOI5   2.1197 0.0672  -0.0563   4.2956  False\n","0_1_nbAOI1 1_1_nbAOI1   0.0935    0.9  -2.0824   2.2695  False\n","0_1_nbAOI1 1_1_nbAOI2  20.4984  0.001  18.3225  22.6744   True\n","0_1_nbAOI1 1_1_nbAOI3    4.471  0.001    2.295    6.647   True\n","0_1_nbAOI1 1_1_nbAOI4   3.2437  0.001   1.0677   5.4197   True\n","0_1_nbAOI1 1_1_nbAOI5   3.3817  0.001   1.2057   5.5576   True\n","0_1_nbAOI2 0_1_nbAOI3   2.7365 0.0015   0.5605   4.9125   True\n","0_1_nbAOI2 0_1_nbAOI4  -5.1986  0.001  -7.3745  -3.0226   True\n","0_1_nbAOI2 0_1_nbAOI5  -7.5269  0.001  -9.7029  -5.3509   True\n","0_1_nbAOI2 1_0_nbAOI1 -11.4328  0.001 -13.6088  -9.2569   True\n","0_1_nbAOI2 1_0_nbAOI2   6.9573  0.001   4.7813   9.1333   True\n","0_1_nbAOI2 1_0_nbAOI3  -7.8884  0.001 -10.0643  -5.7124   True\n","0_1_nbAOI2 1_0_nbAOI4  -7.5342  0.001  -9.7102  -5.3582   True\n","0_1_nbAOI2 1_0_nbAOI5  -9.0148  0.001 -11.1907  -6.8388   True\n","0_1_nbAOI2 1_1_nbAOI1 -11.0409  0.001 -13.2169  -8.8649   True\n","0_1_nbAOI2 1_1_nbAOI2    9.364  0.001    7.188    11.54   True\n","0_1_nbAOI2 1_1_nbAOI3  -6.6634  0.001  -8.8394  -4.4875   True\n","0_1_nbAOI2 1_1_nbAOI4  -7.8907  0.001 -10.0667  -5.7148   True\n","0_1_nbAOI2 1_1_nbAOI5  -7.7528  0.001  -9.9287  -5.5768   True\n","0_1_nbAOI3 0_1_nbAOI4  -7.9351  0.001  -10.111  -5.7591   True\n","0_1_nbAOI3 0_1_nbAOI5 -10.2634  0.001 -12.4394  -8.0874   True\n","0_1_nbAOI3 1_0_nbAOI1 -14.1693  0.001 -16.3453 -11.9934   True\n","0_1_nbAOI3 1_0_nbAOI2   4.2208  0.001   2.0448   6.3967   True\n","0_1_nbAOI3 1_0_nbAOI3 -10.6249  0.001 -12.8008  -8.4489   True\n","0_1_nbAOI3 1_0_nbAOI4 -10.2707  0.001 -12.4467  -8.0947   True\n","0_1_nbAOI3 1_0_nbAOI5 -11.7513  0.001 -13.9272  -9.5753   True\n","0_1_nbAOI3 1_1_nbAOI1 -13.7774  0.001 -15.9534 -11.6014   True\n","0_1_nbAOI3 1_1_nbAOI2   6.6275  0.001   4.4515   8.8035   True\n","0_1_nbAOI3 1_1_nbAOI3  -9.3999  0.001 -11.5759   -7.224   True\n","0_1_nbAOI3 1_1_nbAOI4 -10.6272  0.001 -12.8032  -8.4513   True\n","0_1_nbAOI3 1_1_nbAOI5 -10.4893  0.001 -12.6652  -8.3133   True\n","0_1_nbAOI4 0_1_nbAOI5  -2.3283 0.0215  -4.5043  -0.1524   True\n","0_1_nbAOI4 1_0_nbAOI1  -6.2343  0.001  -8.4102  -4.0583   True\n","0_1_nbAOI4 1_0_nbAOI2  12.1558  0.001   9.9799  14.3318   True\n","0_1_nbAOI4 1_0_nbAOI3  -2.6898 0.0021  -4.8658  -0.5138   True\n","0_1_nbAOI4 1_0_nbAOI4  -2.3356 0.0206  -4.5116  -0.1597   True\n","0_1_nbAOI4 1_0_nbAOI5  -3.8162  0.001  -5.9922  -1.6402   True\n","0_1_nbAOI4 1_1_nbAOI1  -5.8424  0.001  -8.0183  -3.6664   True\n","0_1_nbAOI4 1_1_nbAOI2  14.5626  0.001  12.3866  16.7385   True\n","0_1_nbAOI4 1_1_nbAOI3  -1.4649 0.6398  -3.6409   0.7111  False\n","0_1_nbAOI4 1_1_nbAOI4  -2.6922 0.0021  -4.8681  -0.5162   True\n","0_1_nbAOI4 1_1_nbAOI5  -2.5542 0.0053  -4.7302  -0.3782   True\n","0_1_nbAOI5 1_0_nbAOI1  -3.9059  0.001  -6.0819    -1.73   True\n","0_1_nbAOI5 1_0_nbAOI2  14.4842  0.001  12.3082  16.6601   True\n","0_1_nbAOI5 1_0_nbAOI3  -0.3615    0.9  -2.5374   1.8145  False\n","0_1_nbAOI5 1_0_nbAOI4  -0.0073    0.9  -2.1833   2.1687  False\n","0_1_nbAOI5 1_0_nbAOI5  -1.4879 0.6152  -3.6638   0.6881  False\n","0_1_nbAOI5 1_1_nbAOI1   -3.514  0.001    -5.69   -1.338   True\n","0_1_nbAOI5 1_1_nbAOI2  16.8909  0.001  14.7149  19.0669   True\n","0_1_nbAOI5 1_1_nbAOI3   0.8635    0.9  -1.3125   3.0394  False\n","0_1_nbAOI5 1_1_nbAOI4  -0.3638    0.9  -2.5398   1.8121  False\n","0_1_nbAOI5 1_1_nbAOI5  -0.2259    0.9  -2.4018   1.9501  False\n","1_0_nbAOI1 1_0_nbAOI2  18.3901  0.001  16.2141  20.5661   True\n","1_0_nbAOI1 1_0_nbAOI3   3.5445  0.001   1.3685   5.7204   True\n","1_0_nbAOI1 1_0_nbAOI4   3.8986  0.001   1.7227   6.0746   True\n","1_0_nbAOI1 1_0_nbAOI5   2.4181 0.0126   0.2421    4.594   True\n","1_0_nbAOI1 1_1_nbAOI1   0.3919    0.9  -1.7841   2.5679  False\n","1_0_nbAOI1 1_1_nbAOI2  20.7968  0.001  18.6209  22.9728   True\n","1_0_nbAOI1 1_1_nbAOI3   4.7694  0.001   2.5934   6.9454   True\n","1_0_nbAOI1 1_1_nbAOI4   3.5421  0.001   1.3661   5.7181   True\n","1_0_nbAOI1 1_1_nbAOI5   3.6801  0.001   1.5041    5.856   True\n","1_0_nbAOI2 1_0_nbAOI3 -14.8456  0.001 -17.0216 -12.6697   True\n","1_0_nbAOI2 1_0_nbAOI4 -14.4915  0.001 -16.6675 -12.3155   True\n","1_0_nbAOI2 1_0_nbAOI5  -15.972  0.001  -18.148 -13.7961   True\n","1_0_nbAOI2 1_1_nbAOI1 -17.9982  0.001 -20.1742 -15.8222   True\n","1_0_nbAOI2 1_1_nbAOI2   2.4067 0.0135   0.2308   4.5827   True\n","1_0_nbAOI2 1_1_nbAOI3 -13.6207  0.001 -15.7967 -11.4447   True\n","1_0_nbAOI2 1_1_nbAOI4  -14.848  0.001  -17.024  -12.672   True\n","1_0_nbAOI2 1_1_nbAOI5   -14.71  0.001  -16.886 -12.5341   True\n","1_0_nbAOI3 1_0_nbAOI4   0.3542    0.9  -1.8218   2.5301  False\n","1_0_nbAOI3 1_0_nbAOI5  -1.1264    0.9  -3.3024   1.0496  False\n","1_0_nbAOI3 1_1_nbAOI1  -3.1525  0.001  -5.3285  -0.9766   True\n","1_0_nbAOI3 1_1_nbAOI2  17.2524  0.001  15.0764  19.4284   True\n","1_0_nbAOI3 1_1_nbAOI3   1.2249  0.897   -0.951   3.4009  False\n","1_0_nbAOI3 1_1_nbAOI4  -0.0024    0.9  -2.1783   2.1736  False\n","1_0_nbAOI3 1_1_nbAOI5   0.1356    0.9  -2.0404   2.3116  False\n","1_0_nbAOI4 1_0_nbAOI5  -1.4806  0.623  -3.6565   0.6954  False\n","1_0_nbAOI4 1_1_nbAOI1  -3.5067  0.001  -5.6827  -1.3307   True\n","1_0_nbAOI4 1_1_nbAOI2  16.8982  0.001  14.7222  19.0742   True\n","1_0_nbAOI4 1_1_nbAOI3   0.8708    0.9  -1.3052   3.0467  False\n","1_0_nbAOI4 1_1_nbAOI4  -0.3565    0.9  -2.5325   1.8194  False\n","1_0_nbAOI4 1_1_nbAOI5  -0.2186    0.9  -2.3945   1.9574  False\n","1_0_nbAOI5 1_1_nbAOI1  -2.0261 0.1051  -4.2021   0.1498  False\n","1_0_nbAOI5 1_1_nbAOI2  18.3788  0.001  16.2028  20.5548   True\n","1_0_nbAOI5 1_1_nbAOI3   2.3513 0.0188   0.1754   4.5273   True\n","1_0_nbAOI5 1_1_nbAOI4    1.124    0.9  -1.0519      3.3  False\n","1_0_nbAOI5 1_1_nbAOI5    1.262 0.8573   -0.914    3.438  False\n","1_1_nbAOI1 1_1_nbAOI2  20.4049  0.001   18.229  22.5809   True\n","1_1_nbAOI1 1_1_nbAOI3   4.3775  0.001   2.2015   6.5534   True\n","1_1_nbAOI1 1_1_nbAOI4   3.1502  0.001   0.9742   5.3262   True\n","1_1_nbAOI1 1_1_nbAOI5   3.2882  0.001   1.1122   5.4641   True\n","1_1_nbAOI2 1_1_nbAOI3 -16.0275  0.001 -18.2034 -13.8515   True\n","1_1_nbAOI2 1_1_nbAOI4 -17.2547  0.001 -19.4307 -15.0788   True\n","1_1_nbAOI2 1_1_nbAOI5 -17.1168  0.001 -19.2927 -14.9408   True\n","1_1_nbAOI3 1_1_nbAOI4  -1.2273 0.8945  -3.4033   0.9487  False\n","1_1_nbAOI3 1_1_nbAOI5  -1.0893    0.9  -3.2653   1.0867  False\n","1_1_nbAOI4 1_1_nbAOI5    0.138    0.9   -2.038   2.3139  False\n","--------------------------------------------------------------\n"]},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAX4AAAEHCAYAAACp9y31AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU9b3/8dc3IaSEPYEWhGBrbcUgUFEksttiK9CHC0QwqNSlt6J1qT+uWkUpdaktXq5LVS51o1AJ0LDUCliXWxHBIIICkqL1ViAJULMYE0kMyeT7+2NmQhKyzCRz5kxm3s/HYx7MnDnLZw7JJ2e+5/v9fI21FhERiR1xbgcgIiLhpcQvIhJjlPhFRGKMEr+ISIxR4hcRiTFK/CIiMaaT2wEEwhijPqciIm1grTWNl3WIxA+g8QYiIsEx5qScD6ipR0Qk5ijxi4jEmA7T1CMiEipffvkln332WbNNIR1NQkICp5xyCnFxgV3LK/GLSMwpLi4mNTWVhIQEt0MJibKyMg4fPszAgQMDWl9NPeK6irx8t0OQGFNbWxs1SR+gR48eVFdXB7y+Er+4qmzfPnZcdRVlubluhyISM5T4xTXW42H/Q78Ba9n/0ENYj8ftkETa5Ze//CVLly519Bi/+MUvOOuss3jkkUfavA+18YtrCtaupaq4GIDjRcUUrFvHwIwMl6MSiUw1NTV06tSJVatWcfjw4XbdmNYVv7gmb+UqaisrAfBUVpKXtdLliCRWHThwgBEjRjBr1iy+/e1vc9999/Hcc89xzjnncP7551NaWsqOHTs499xzGTp0KDfeeCMe3zfUxYsX893vfpeJEyfyr3/9q26f77zzDmPHjmXEiBFkZmby1VdfAfCNb3yDOXPmkJaWxtVXX01NTQ0Af/3rXxk1ahTf+973uOWWWxrEde2113LOOeeQkZFBUVERZ599Nq+//nqbP68Sv7gm9YqZxHfpAkB8ly6kZl7hckQSy3Jzc3nwwQfJzc3lhRdeoLS0lJ07d5Kens7q1au59tpreeaZZ9i7dy8lJSWsXLmSgoICHnvsMXbu3MlLL73Ee++9B8Dx48e56667ePnll9m1axdnnnkmzz77LACfffYZl1xyCbm5ucTFxZGVlUVhYSFPPPEEb731Fh988AHHjh3j5ZdfBmDPnj3853/+J7t37yY7O5uUlBQ++OADJk2a1ObPqqYecc2AadM4vG49lfn5dO6TwoDLLnM7JIlhaWlpnHbaaQCcdtppXHjhhQAMHTqUXbt2UVtby9lnnw3AlVdeyaZNm+jatSuTJk2ie/fuAEyePBmAjz76iL179zJx4kTA+4dgypQpACQlJdWtl5GRwYYNG+jVqxd79uxh1KhRAFRWVjJ8+HDOOusszjzzTIYMGRLSz6rELyGVV5pHaq/UgNY18fEMvnce79/0cwbPuxcTH+9wdCLN69y5c93zuLi4utdxcXFUV1c3aFP31w5rXEOs/vKRI0fy6quvnnScxm3zxhistVxyySX84Q9/aPDegQMH6Nq1azs+VdPU1CMh8+HRD8n8Uyb7ju4LeJseaWmMXL6cHmlnOhiZSPv07t2buLg4du/eDcDKlSsZO3Ys5513Hq+//jrl5eWUl5fzyiuvADB48GA+/fRT9u7dC0B5eTmffvopAMeOHWPTpk0ArFmzhtGjR5Oens4bb7xBQUEBAIWFhRw5csSxz6PELyHhqfXw4GsPYq3lgdcewFMbeNfMpNTARhuKuOn555/n+uuvZ+jQofTs2ZMrrriCAQMG8Itf/IJzzz2XjIwMxowZA3i/PaxYsYIbbriB4cOHM27cOA4ePAh4b+6+9tprDB8+nJqaGjIzM/n617/OU089xcUXX8ywYcOYMmUKJSUljn0W0xHKHRtjbEeIM5at+mAVz+Q8Q2V1JUkJSfzs/J9x+fDL3Q5LpEmffvop3/rWt1w5dr9+/Th69GjI99vUZ/I1I53U71NX/BISWbuyqKz2ds2sqK7gxV0vuhyRiDRHiV9CInNEJkkJSQAkJSRx5YgrXY5IJDI5cbUfLCV+CYmMYRmkdE0BIKVrCtOGTnM5IhFpjhK/hER8XDz3XXgfcSaO+RfOJz5OXTNFIpX68UvIDOk3hBVXrQi4H7+IuENX/BJSSvoikU9X/CIijfzuif/h0L/b349+0DeSuevWOS2us2TJEv74xz+SkJDAc889xymnnMI111zDkSNHSEtLY/HixQFPqRgoJX5xXcGatQyYrpvBEjkO/buEnOMhGFj475ZnlyspKeH5559n27ZtvP/++9x9991MmDCBUaNGMXfuXG6++WY2bdrE1KlT2x9LPY419RhjTjHGbDfGbDbGbDPGDDPGJBljVhtjthhjlhhj1NQkIjFr+/btXHDBBcTHx3Puuefy8ccfs2XLlrpEP3XqVLZs2RLy4zqZeP8NnG+tnQDcC9wJXAdst9aOA6qByQ4eX0Qkon3++ef06tWr7rW1tsGy3r17O1K6wbHEb631WGtrfS97AO8D44ANvmUbfK9FRGJS7969+eKLL+pex8XFNVhWWlpKcnJyyI/raFOLMSbNGLMN+D2wBegNlPre/hw46RMZYxYYY2z9h5Mxioi4ZdSoUbz55pt4PB527drFd77zHcaPH8+GDd7r440bNzJuXOivjx29uWutzQVGG2O+BywBDgA9gaNAL+Ck7zDW2gXAgvrLlPzb51BhGYP69nA7DJEOY9A3klu9MRvwflqQnJzMT37yE8aNG3dSr55x48aRlpZWN2lLKDlWndMYk2itrfI9PxVYCmQDidba/zbGPAH8zVq7oYXd+Pel6pxttPdgIdc9tYnnb57M0EF93Q6nSerVI+HmZnVOp0RKdc6Rvh49fwf+CMwFXgDSjTFbgERgk4PHj3me2lrmr9xKrYX5WVvx1Na2vpGIRD3HmnqstW8DE5p4a4ZTx5SGVm3dT1F5BQBF5RWs3vYRmWM105VIrFM/+ii2fHMuFVU1AFRU1bDszcCnRBSR6KXEH8WunpBGUqL3S11SYidmTxzi6PGyd2c7un8RCQ0l/ig2c8xg+nT3To7Sp3sSM0af4XJEIhIJlPijWHxcHPdnjiHOGB7IHEt8iAs9hcInjz9OZX6e22GIuGbJkiWMHj2aCRMm8Mknn7BhwwbS0tIajOgNNRVpi3JDB/VlzR2XqB+/SBCW/v63VBQebPd+kvqeyjW3/LLZ95sq0rZkyRJ27tzJyJEj23385ijxxwAlfZHgVBQe5Med3m73fl4ubPn9poq0OVGiobHI++4vIhIjmirSFg5K/CIiLmmqSFs4KPGLiLikqSJt4aDELyLikvpF2m6//XYefvhhtm/fzqRJkzhw4ACTJk3i1VdfDflxdXNXXFVZUADA3jvvZOjChS5HI+KV1PfUVm/MBrqf1syZM4c5c07My3v66afz+uuvt//gLVDiFxFppKUumNFATT0iIjFGV/ziinczZzW77LysFeEORySm6IpfRCTGKPFLyOR9kcejbz3qdhgi0golfhERl1RVVTF69Gh69epFdra3rHlFRQUzZsxg3Lhx3HDDDdQ6MHOe2vglJOa+NLfB80UXL3IxGpH2Wfj0QvKK2181NjUllTtvurPZ9xMSElizZg1LliypW/b8888zatQo5s6dy80338ymTZuYOnVqu2OpT4lfRKSRvOI8dvXa1f4dFbf8dlxcHP3792+wbMuWLfz6178GYOrUqWzevDnkiV9NPSIiEaR+4bbevXtTUlIS8mMo8YuIRJD6hdtKS0sdKdOsxC8iEkHGjx/Phg0bANi4cSPjxo0L+TEca+M3xpwJPAPUAh7gemA8cB/gv2sy2Vpb6VQMIiKRbvr06bz//vt069aNd955hwceeIBrrrmGcePGkZaWxuTJk0N+TCdv7hYBP7bWlhpjLgLuAd4GFltr/8vB44qItEtqSmqrN2YD3k8r1qxZc9Ky1atXt//gLXAs8Vtr69e2q8F71Q/wU2PMJcB6a636/IlIxGmpC2Y0cLyN3xiTBNwPPAasB4YA3wfGGWO+38T6C4wxtv7D6RhFRGKJo4nfGNMJWAkstNb+w1pbaq31WGurgbXAOY23sdYusNaa+g8nYxQRiTWOJX5jjAGeAzZZa9f7lvWst8oE4BOnji8iIk1z8ubuj4DLgVONMTOBD4AyY8yP8Lb378Lb9CMiImHk5M3dV4CkJt6a79QxRUSkdarVI+02c9nMJpetmr3KhWhE2u/ZhQspy8tv9356pA7kp3c230OoqqqKCy64gNzcXJ599lkyMjLYsGEDd9xxB4cPH6a0tLTdMTRFiV/CZvP4CUGvN+GtzU6FI9Kssrx8ztm9u9372dnK+01V5zz//PPZuXMnI0eObPfxm6PELyLikqaqczpRm+ek4zp+BBERiShK/CIiMUaJPwas3Lrf7RBEJIKojV9ExEWNq3POmDGDefPmceDAASZNmsSdd97JD3/4w5AeU4lfRKSRHqkDW+2RE+h+WtNUdc7XX389BEdvnhK/iEgjLfW9jwZq4xcRiTFK/CIiMUaJX5pUXXzQ7RBEHBMXF0d1dbXbYYRMWVkZCQkJAa+vNn45SVX+bv79wmy+ce1yEgcOczsckZBLSUkhLy8Pb/X4ji8hIYFTTjkl4PWV+KUBW+uheP08sLUUr7+H/jf9BRMX73ZYIiHVrVs3unXr5nYYrlFTjzRQviMLz5fe6ZI9XxZSviPL5YhEJNSU+KWB8m1LsccrALDHKyjfttTdgEQk5JT4pYHuo6/BdPbOn2M6J9F99DXuBiQiIafELw10H5lJfLe+DJq/l/hufek+MtPtkEQkxJT4pQETF0/Kpb8BIOWyh3VjVyQKKfHLSRIHDqOm5BCJA4a6HYqIOECJX0Qkxijxi4jEGMcGcBljzgSeAWoBD3A9cBRYCvQHcoEbrbW1TsUgbVddcohOyYNCtr+cnBx2fFUZ9HbHNm4kOTmZ9PT0kMUiEuucHLlbBPzYWltqjLkIuAf4ANhurV1kjHkSmAxscDAGccCY348Jer15357H557g/8YfPXo06G1EpGWOJX5rbWG9lzV4r/rHAb/yLdsATECJPyYkJyfTOz74lsV+/fqRnJzsQEQiscvxWj3GmCTgfrxNPY8Dpb63PgdO+o02xizgxB8HiRLp6elUfa1L0NtNmDLFgWhEYpujN3eNMZ2AlcBCa+0/8Cb7nr63ewEljbex1i6w1pr6DydjFBGJNY4lfuOtd/ocsMlau963+C1gqu/5FGCLU8cXEZGmOXnF/yPgcmCmMeZNY8xjwAtAujFmC5AIbHLw+NIONSWH3A5BRBzi5M3dV4CkJt6a4dQxRZxQXXyQhJRT3Q5DJGQ0gEukBVX5uzny9MVU5e9xOxSRkFHiF2lG49nIbK3H7ZBEQkKJX6QZmo1MopUSv0gzNBuZRCtNti5BycnJoeqfVUFvt3HjRvKOVzG4c6IDUTmj++hr+OLvv6dPxiKKsudqNjKJGgFd8Rtjbm30urMx5mFnQpJQemT9u+QVloVsfyUlJXi+9AT9OHr0KOW1Hasen382MkCzkUlUCbSp5zvGmLeNMYONMeOBHcAXDsYlESo5OZn4bvFBP/r160f3OPdbFg8F8UfQPxtZTckhzUYmUSWgph5r7S2+Cpu78Cb8Cdbajx2NTCJSeno6iTuCb66ZMmUKm3/7OwciCtzeg4Vc99Qmnr95MkMH9Q1om8SBwzh++EPNRiZRJdCmnouA/wJ+CfwV+IMx5nQnAxMJJU9tLfNXbqXWwvysrXiCaHaqKTnoYGQi4Rfozd3bgCnW2kMAxpiJwBpguENxicucSHYT3tpc9/zdzFnNrnde1oqQH3vV1v0UlXt76BSVV7B620dkjj0z5McR6QgCuuK31k72J33f6zeBUU4FJRJqyzfnUlFVA0BFVQ3L3twX0HaFK26kpuQQhStudDI8kbBq8YrfGPMba+09xpgswDaxSvOXbSIR5OoJaSz+2wdUVNWQlNiJ2ROHuB2SiGtaa+pZ6/v3f5wORELv1ufeaPD8iet/ENB2/qvbwhU30nfWYkdiC7eZYwbz520fc6iqjD7dk5gx+owW1z/85NRml51ysyaNk46ttaaePwBYazcDc6y1m+s/nA9PJDTi4+K4P3MMccbwQOZY4iOga6mIW1q74q8/+1XLl0gSUS793boml62/6zIXookMQwf1Zc0dlzCob48m3z90f2BdNuuvN2j+3pDEJhJOrfbqMcYk4P1mYHzP6/4YWGuPOxibRDF/z529d95Zt2zowoWOH7e5pC8SS1pL/L2BjziR7OsP2rLAaU4EJSIizmkx8VtrvxmmOEREJEwCGsBljIkDMoExeK/0twIrrbUdq+qWtMiNnixdBgwA4PTbbnNk/yJyskBH7r6AN+Fn+15PBy4CZjsRlIgTHln/LgB3XHqey5GIuCvQxH+utbb+iJeXjTEfOBGQiIg4K9DE/5Yx5ofW2lcBjDE/Al5vaQNjTCLwdyAN+Km1NtsYcw1wH5DnW22ytbayTZGLa7besrXB65nLZja53qrZq8IRjogEqcVRLMaYI8aYw8BlwCvGmHJjTBmwidbLNVTjbRJ6rNHyxdbaib6Hkr6Exa3PvUFecTl5xeUNRjSLxKLWevX09z/3lWE+tbVt6m1bCxwxxjR+66fGmEuA9dbaRcGFKyIi7RVor56ngPOBPZwo1maBvwV5vPXAcrzfNP5sjHnfWvu/Qe5DRETaIdA2/u8DQ9rbfdNaW+p76jHGrAXOARokfmPMAuBX7TmOiIg0L9BKVe/hbeZpF2NMz3ovJwCfNF7HWrvAWmvqP9p7XBEROSHQK/40YJ8x5h9AFd4SDtZaO7qljYwxa4CzgS+NMecDx3w9gjx45+9d3+bI5STn3LEs6HV2PqKhGAA5OTl8fMAT9HZ9Nm4kOTmZ9PR0B6IScUagiX9aW3ZurZ3exOL5bdmXiJNKSkoobEMfs5qjR0MfjIjDAu2ho9mmpVmrZq9i7ktzGyxbdHFwHbbKcnPpkZYWyrCCkpycTN8uwW/Xp18/kpOTQx+QiIMCveIXCTnr8VCy/V0GTJ/O/oceYuSyZZj4eFdiSU9P55RXgz/2oClTHIhGxFmahkhcU7B2LVXFxQAcLyqmYN3Jk8eISOgp8Ytr8lauoraykk8efxxPZSV5WSvdDimmHCosczsEcYkSv7gm9YqZxHfxNqzHd+lCauYVLkcUO/YeLGT6I+vZe6jQ7VDEBWrjj3FuzjM7YNo0Dq9bT2V+Pp37pDDgMmfmA9b8ww15amuZv3IrtRbmZ20l+46LNfl8jNH/trjGxMcz+N55EBfH4Hn3unZjN9as2rqfovIKAIrKK1i97SOXI5JwU+IXV/VIS2Pk8uX0SDvT7VBixvLNuVRU1QBQUVXDsjf3uRyRhJsSv7guKXWg2yHElKsnpJGU6G3lTUrsxOyJQ1rZQqKNEr9IjJk5ZjB9uicB0Kd7EjNGn+FyRBJuSvwiMSY+Lo77M8cQZwwPZI7Vjd0YpP9xCYlFFy9iYK+BDOw1MOhyDRJ+r+z6lBmjz+CsQX3cDkVcoMQvIhJj1I9fxKf++ITDT05tdr1Tbt4QjnBEHKPELyGT2jOVjOEZbochDqouPkhCSrvnZBKXqalHJMbc+twb5BWXk1dczq3PvRHwdlX5uzny9MVU5e9xMDoJB13xR4mcnByqC3KD2qa2vJCnqSaps+GbPQOf4bKlWafySvNI7ZUaVBzRKprOha31ULx+HthaitffQ/+b/oKJ00jrjkqJP0qUlJRgK4Ortlh7rJQjQNfjlq6dA0/8zc06Nfgbg8n8UyZLMpYwpJ97g4ICmYKyqfXqT0Ppb8cvXHFj3bK+sxYHHMOHRz9kTvYc189FqJTvyMLzpbegm+fLQsp3ZNFj1FUuRyVtpaaeKJGcnIzp0iOoR1zXXvTvCv26Gfp2IeBHvyZmnfLUenjwtQex1vLAaw/gqQ1+/tpoEY3nonzbUuxxb30fe7yC8m1L3Q1I2kVX/FEiPT2dhDUfB73dTd3fDXqbpmadyt6TTdGxIgCKjxWzdu9aLh9+edD7jgbReC66j76GL/7+e/pkLKIoey7dR1/jdkjSDrril5DI2pVFZbV3tvKK6gpe3PWiyxGFRt9Zi+mUPCioZp5oPBfdR2YS360vNSWHiO/Wl+4jM90OSdpBiV9CInNEJkkJ3vovSQlJXDniSpcjck80ngsTF0/Kpb8BIOWyh3Vjt4NzLPEbYxKNMduMMaXGmAzfsiRjzGpjzBZjzBJjjP7wRImMYRmkdE0BIKVrCtOGTnM5IvdE67lIHDjM+++AwCbvkcjlZOKtBqYDj9Vbdh2w3Vo7zvf+ZAePL2EUHxfPfRfeR5yJY/6F84mP4SvC9pyLirx8ByNrv5qSg26HICHgWOK31tZaa480WjwO8I933+B7LVFiSL8hrLhqBWn90twOxXVtORdl+/ax46qrKMsNbjyGSLDC3dTSGyj1Pf8cSG5hXemAomXAkl9V/m46JZ/aptGqwZwL6/Gw/6HfgLXsf+ghrKfjdwGVyBXu7pyfAz2Bo0AvoKTxCsaYBcCvwhtWdKg/AKmpCcaBkyYYP3T/I47G1JH5R6v2vuiXQY9Wzd6dHVTdooK1a6kqLgbgeFExBevWMTAjOuoePfrWowDcPv52lyMRv3Bf8b8F+MseTgG2NF7BWrvAWmvqP8IaoYiPf7Rql9PH1o1WdUreylXUVnq7gHoqK8nLWunYscJp7ktzyS/NJ780su9dxBpHE78xZg0wG5hvjFkEvACkG2O2AInAJiePL9Ie/tGqh+4f6vho1dQrZhLfpQsA8V26kJp5hWPHEnG0qcdaO72JxTOcPKYEJ9pq0LelWJ3fxkbF5/yjVe3xCkznJEdHqw6YNo3D69ZTmZ9P5z4pDLjsstY3aoOmmgAv/d26k5oAJbqpH71EFX+xurY8jh49SknJidtO/tGqgOOjVU18PIPvnQdxcQyedy8mPna7w4rzVKtHooq/WF1bNC4+5x+t+u8Xrg7LaNUeaWmMXL6cpNSBjh5HRIlfokpbi9UBTGmi+FziwGH0v+mloGedyvsij0ffejToniyRnPT9JaoLV9wYVO0iiTxq6hFphaYalGijxB+l1t91GYP69Gjw0A086UgivXxFR6bELxJBCtasdTuEiKDyFc5SG79IFAvFNJRNdfP1L3Oim2/j8hUjly1TL6cQ0xV/FHvi+h+QmtKd1JTu/MeFw9wORyQgTZWviHWhbvZS4o9intrauufzs7Y2eC0SqaK1fEVbOdHspcQfxVZt3c9L733Cyq37KSqvYPW2j9wOSaRVqVfMZMD0aQyYPi3my1c4VbVViT+KLd+cS0VVDQAVVTUse3OfyxGJtG7AtBMzljlZvsIteaV5Aa/rVLOXEn8Uu3pCGkmJ3vv3SYmdmD1xiMsRibSu/o3caCtf8eHRD8n8Uyb7jgZ2EeZUs5cSfxSbOWYwfbp7J/3u0z2JGaPPcDkiacknjz9OZX7gV4PRrLKggMqCAg4ufSEsxztUWOb4MTy1Hh587UGstTzw2gN4altvtvFXbT39tttC2uyl7pxRLD4ujvszx3Ddk6/wQOZY4uNa/jvv75rnH5oPaGh+GFUWFACw9847GbpwoauxHLo/sAnV669Xv9IrwMxlM5t8vWr2qnZGF1p7DxZy3VObeP7myQwd1Dfg7aqLDwY1qjt7TzZFx4oAKD5WzNq9a7l8+OUtbuOv2gqhbfbSFX+UGzqoL2vuuISzBvVxO5SYoclHOg5PbS3zV26l1gbX860qfzdHnr44qCk5s3ZlUVntbbapqK7gxV0vtrqNiY8nedR5VObnhbTZS4k/Bgzq27ZqlRIe72bO4t3MWVTm5dc9/MvEWat8Pd6AgHu++afkxNZSvP4ebABNNgCZIzJJSvA2vSYlJHHliCuDirVH2plBrd8SJX4RiVlt6fnmn5ITCGpKzoxhGaR0TQEgpWsK04ZOa2UL56iNX07Sd9ZiPn/lYXpfdLfboYgLaooO8GZx8P3F+zSawawjuHpCGov/9gEVVTUB93zzT8kJ1E3J2WPUVa1uFx8Xz30X3sec7DnMv3A+8QHO7+DEvR8lfok69evMQNPTDQKuVivdPH5C0OtNeGuzU+E0YKsqKLTBb1dz9Gjog3HYzDGD+fO2jzlUVRZwzzf/lJy9vn8bpf/7eFBTcg7pN4QVV60gtVdqO6JuPyV+OUlV/m46JZ9KVf4eEgeqxk8wOkpPlpaYxCT6muC369NoBrOOINieb+CdkvPLHSupKTnYpik53U76oMQvjfhvXHU/bxbF6++h/01/cXzKQXFGeyae52vQ62uG7/UL/DbgoCZmMOsI/D3fAu0E4Z+Ss+LDDUFPyZm9O5uM4RltDTVklPilAf+Nq07Jg+puXAXSfimRxz/xfFvUTPpPOvXrx6ApU5osy+znRFlmNwTb863sLe/4lrLNT3fIsS6uJH5jzDFgh+/l49Za1V2NEP4bV/5BXIHeuJLIE8qJ58OlqS6s72bO4rysFWGPJZq5dcX/qbV2okvHlhb4b1zZ4xWYzklB3biSyBLqieclvJPSOPlH0K3En2qM2QwUALdZawtdikMaae+NK2ldTk4OO76qDHq7Yx2wu6REJrcS/2nW2mJjzAxgETC7tQ0kPPw3rv79wtVB37iSwJSUlPC5J/hJcY5GeHfJMb8fE/R6W2/Z6lQ4ESnvizwefetRbh9/u6txuJL4rbXFvqd/BubVf88YswD4VbhjkhMSBw6j/00vBVWAKla1JdktGrmI3vHBD5p3q93daYGMaWi8TrjGNEBoCtZFmrAnfmNMV+Ara60HGAccqP++tXYBsKDRNm0YTiLtoaTvnPT0dKq+1iXo7Sao3d0Rj6x/F4A7Lj3P0ePMfWmuo/sPhhtX/IOBZ4wxXwI1wA0uxCASEzrCKGY33frcGw2eP3H9D1yMJnzffsKe+K21O4ER4T6uiIh4qTqniMSkS3+3jkNFZQ0ezX0jijYauSsiLdLMbNFHiV9EAtJj/BwqPtxI0lnNl3CINjk5OXx8IPpKVCvxi0irYrV4X0lJCYXBj7VrU4nqcA7sU+IXaaOcnBE8sYYAAAzrSURBVByq/lkV9HYbN24keeHv6n5RW5piMdQ1atbfdVmDnixAQD1ZWive155zkXe8isGdE4PeNljn3LEs6PVqig7w8NX/Vfe65JXfNrtd8kW/bPjaN+aicanu+svql+sO58A+JX6Jem1Ndq0pKSnB82XwzQCRPgK3Ka0V72vrudi+fTufffUV5QFOcu4XrvIVnfp8s0HdosP/eqrZdU9p5ziL5OTksA3sU+IXaaPk5GTiuwXf3NERR+C2Vryvreeic+fO1EDQV7qR/sezreUrwjWwT4lfpI3S09NJ3BF8E4XblS+fuP4HdaNVLxrxrYC2aa14X1vPxQ9G/oC3//KXoLcL9o9neyal2RjhN2rbQolfxGX+dvy9d95ZtyxUk2o3xVOvWWV+1lay77i41SkHnSreF67yFe2ZlKb+twunu7bWH4Xb3L2fjlyWWURcsmrrfl567xMqqmpISuzE6m0fkTn2zFa368jF+0I5KY2t9VBdkkeX08dQ+clWbK2nw/VwUuIXiRBdBgwA4PTbbnP0OMs351JRVQNARVUNy97cF1Dih45bvC+Uk9L4eziVv7sC0zkppD2cwtWkpMTvkoq8fJJSB7odhrRT43ryTXXdg4bd9tx29YQ0Fv/tg7or/tkTh7gdUofi7+EEYI9XhKyHUzhvWCvxu6Bs3z7ev+nnnL34aXqkpbkdjkSIr0+aRPn+jyjLzXX052LmmMH8edvHHKoqo0/3JGaMPiMk+23rH8FwtWuHilM9nBo3KZ2XtQLr8fDh3XfXLTvr4YfbHHd9SvyNVBcfdPTrrPV42P/Qb8Ba9j/0ECOXLcPEd6z2QQk9/8/FgOnTHf+5iI+L4/7MMVz35Cs8kDm21Ru70SJUJaqd6uHUVG+vgrVr65oAj27cRMG6dQzMyAh6343Fxv94gKryd3Pk6Yupyt/j2DEK1q6lqtg7AdnxomIK1sVGNUBpmf/n4pPHHw/Lz8XQQX1Zc8clnDWoj6PHiUb+Hk6YOMenJ81buYqCNWspWLMWT2UleVkrQ7JfJX4ffy0SbC3F6+/B1gbfRheIvJWrqK2sZOjChSH9j5SOzf9zAYTt52JQ37b1cgnUqtmrGNhrYN1j1exVrd7rOC9rBedlraBL6sC6RyQ18/j5ezglDghsWsa2Sr1iJvFdvN1d47t0ITXzipDsN2oT/6HC4Prs+u/UA3W1SJyQesVMBkyfRsn2nJD+R0rH5tQvuNsWXbyoLvEHyno8Lb6OFOHo4TRg2jQ6p6QA0LlPCgMuC81MaVGZ+PceLGT6I+vZe6gw4G3Kty2lT8Yi4MSdeicMmDaNyoICKgsK6Dl8WMj+I6Vjc+oXvCMqWLuW0t17SB6Vzhe79zjW7LX+rssY1KdHg0eopqDcesvWusfAngObfdRfrykmPp7B986DuDgGz7s3ZPd9jLWRP4+5McYGGqentpaMR17iUFEZg/r0CGhUIkDZ9j/h+Tyvrm9uzwtuadBFqyV5pXmk9kptdb1wVmGUhpwo0tac+pNqL7p4UcDbleXment7Pf00PdIC61ffETz61qMA3D7+9oDWf2d6BscLT1y0de7bl/PXZDsSG7gz2XowPxfQ9u7fxhistabx8qi74l+1dT9F5d4+tkXlFaze9lFA29W/M9/UnfrmfHj0QzL/lMm+o/uCD1aknh5paYxcvjyqkj5Aas9U1uxZE/DvSLibvS46+1us3rY/qBaCcAv1mJ+ou+Kf/GA2n31RUff66z2T2HRv892fDj/Z/GxC/roczfHUerjyxSvrrvhfvPJF4hvd4d88fkJAcddXv1+zhEZHuOKPRoH8jjRmPR52XD2byvx8uqQOdLRra1tbCDqK5q74o64ffyCjEg/dH9id+PrrDZq/96T3s/dkU3SsCIDiY8Ws3buWy4dfXvd+OGfUEYlErf2ONMXfrv3+TT8Pabt2U5pqIQi0fEVHFvbEb4y5AfgJUA1cb639JJT7949KnDl5MKve3n/SqMRQzqGZtSuLqWnebwzZu7N5cdeLDX6owzmjjkgkytqVRWW19+KnorripN+R5vibvZwua9KeukUdWVgTvzEmGbgOGA2cDTwMtP5TEKD6I/FWvv0PAKY/8pcGd+rbOofmo9nziO8Wf9KIvOzdJ246FX5Z2GBihUUjF4VtRh2JHIsuXlR3QzPWZY7I5NmcZ6moriApIYkrR1wZ8LbhqGUVq3WLwn3FPwr4u7XWA7xnjPlue3aWk5PDz55Y3+p6w2Ztr3teW15IZvqVdOvWje985zsBzaH5z3/+k9q3n8dWBXc/pOTbJYx94glX5laVhh699gL++6X3ANj20WE8tbVR1ZYbqTKGZbBu7zoqSitI6ZrCtKHT3A6pAafqFkW6cCf+3kBpvdcn3XQIRlsmVzCdEunfvz/9+vXz1sbw1cdoaWKFjRs3ErfbmySCqbrXuMkm3BNuyAltrUHfVqk9U8kY3v6aKh1dfFw89114H3Oy5zD/wvmt3tgNt1itWxTWXj3GmMnAeGvt3b7XH1hrv9donQXArxpv21ScOTk5lJSUtCmWYG6etnacomNF9OnadM0T3aSNDMH29pLQCnSsi1sOFZY5XsLCDc316gl34k8GNgBjgeHA3dbaVtv4g+nOKdKUFVtyG7Tl3nTR2TFxE09iW0QM4LLWlgB/BLYAjwJ3t7yFSGjMHDOYPt2TAGKqLVekKVE3gEukOXsPFXLdk6/wws2TVY5YYkJENPW0lRK/hEq0tuWKNEWJX0QkxkREG7+IiLhPiV9EJMYo8YuIxBglfhGRGNNhyjIb067qDiIi4tMhevVEAl/PIv31QeeiPp2LE3QuToj0c6GmHhGRGKPELyISY5T4RURijBJ/4H7tdgARROfiBJ2LE3QuTojoc6GbuyIiMUZX/CIiMSbmE78xZqkx5txm3rvRGHPEGBNfb9kZxpi/GWM2G2PeNMak+5Z/0xjzsu/5VGNMrjGmtKn9RiqHzsUtxph3jTFbjTG/D88naT+HzsXPjDHbfOdiuTGmQ4yjceJc1Fv32cbLIplDPxfXGGP+z/f+m8aYLk5/jphP/K2YBrwE/ADA94v6Z+AOa+0E4GrgeWNMr0bbvQOcA+SHMVantfVcbAJGWWvHAH2NMWPDGLNT2noullprR/vOhQUmhi9kx7T1XGCMOQPoG8ZYndbmcwEsttZO9D0qnQ40phK/MWaiMeavxpjVxpgPjTGX+t66zvdX+e/GmL6+dQcBnwOPA5m+9dKBD621ewCstXnAeuDH9Y9jrS0Jx39ee4TxXHxSr6Z2DRD4bPVhEsZzcdy3D4M38X/i9GcLVrjOhc99wO+c/DztEeZz8VNjzBZjzFxHP5RPTCV+nxTgCmAKcLtv2f9Za38ELAV+4Vt2BfCitTYXONUY8zVgAHCw0f4O+ZZ3RGE7F8aY8cDXrbXvhPQThE5YzoUx5v8B+4E+wGch/gyh4vi5MMaMBI4Ah534ACEUjp+L9cAQ4PvAOGPM90P9IRqLxcT/vrW21lp7CEj2Lcvx/bsd+K7v+TTgZmPMK0B/YCpQAKQ22l+qb3lHFJZzYYwZgvfKblZoww+psJwLa+1/W2vPAD4CrgnpJwidcJyLe4jgq/16HD8X1tpSa63HWlsNrMXbTOyoWEz89fuv+mtpnFfv34+NMWcC/7TWXmitvQi4CO/Xt+3AMGPMWQDGmAHAZcCGsEQeeo6fC99X4KXALGttkVMfJATCcS4S6738HIjU5sBw/I58G/gT8EfgvHA1cbRBOH4uetZ7OYEwNAF2iF4FYXCGMeZVIAGYAdwKvOZ/01p70BjzbSAJmAk85vsqB/Af1trP6//nGWNGAQ8B3zTGvA4stNa+GqbP0l4hPRfAQrxfl1/wNm3zW2vtK2H4HKEQ6nMx3xgzBu8F16d0jCtev5CeC2vtMPD2bgGetNYuCsunCI1Q/1zMNcb8CO/9r114m34cpQFcIiIxJhabekREYpoSv4hIjFHiFxGJMUr8IiIxRolfRCTGKPGLBMAY83NjTFm9bnkYY24zxnzse/zN1zXR/95RN+IUCYQSv0hgZgAfAj8CMMZMwztM/1xr7XeBZ4F1vjo8IhFNiV+kFcaYfnhr69yP9w8AwFzgbmttGYC19s/AF8AkV4IUCYISv0jrMvDWUHkDGOtr7knDO8qyvveBM8Mcm0jQlPhFWnc5kO0rovV3vLVYRDos1eoRaYExpj8wCviLr/m+C94aLf8ARgBv1lv9bGBjmEMUCZqu+EVaNh14zFr7TWvtN/GW1Z0APA08bIzpAWCMuRzojbc5SCSi6YpfpGWXA3f7X1hrjxtj3gaO4Z1Wb6cxxuKdcOMya22tO2GKBE7VOUVEYoyaekREYowSv4hIjFHiFxGJMUr8IiIxRolfRCTGKPGLiMQYJX4RkRijxC8iEmP+P9wlPP+xssaHAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["                 Anova\n","========================================\n","         F Value  Num DF  Den DF  Pr > F\n","----------------------------------------\n","AOI      614.6561 4.0000 284.0000 0.0000\n","mode       0.0538 1.0000  71.0000 0.8172\n","AOI:mode 310.0612 4.0000 284.0000 0.0000\n","========================================\n","\n","#####################################################################\n","3-WAY ANOVA H1: durFix is impacted by the AOI, the operation mode and the performance (label)\n","                               sum_sq     df           F         PR(>F)\n","Intercept                2.183388e+04    1.0    0.061067   8.048903e-01\n","C(mode)                  4.191383e+03    1.0    0.011723   9.138111e-01\n","C(label)                 9.370909e+04    1.0    0.262093   6.088475e-01\n","C(AOI)                   3.062833e+08    4.0  214.159174  6.392899e-120\n","C(mode):C(label)         5.507587e+02    1.0    0.001540   9.687039e-01\n","C(mode):C(AOI)           1.110887e+08    4.0   77.675348   1.592641e-54\n","C(label):C(AOI)          3.343879e+07    4.0   23.381042   3.665160e-18\n","C(mode):C(label):C(AOI)  1.065688e+07    4.0    7.451495   7.018569e-06\n","Residual                 2.502792e+08  700.0         NaN            NaN\n","         Multiple Comparison of Means - Tukey HSD, FWER=0.05          \n","======================================================================\n","   group1      group2    meandiff  p-adj    lower      upper    reject\n","----------------------------------------------------------------------\n","0_0_durAOI1 0_0_durAOI2  3688.9829  0.001  3187.5585  4190.4073   True\n","0_0_durAOI1 0_0_durAOI3  2219.9967  0.001  1718.5723  2721.4211   True\n","0_0_durAOI1 0_0_durAOI4  1525.6784  0.001   1024.254  2027.1028   True\n","0_0_durAOI1 0_0_durAOI5   506.9389 0.0441     5.5145  1008.3633   True\n","0_0_durAOI1 0_1_durAOI1     72.153    0.9  -429.2714   573.5775  False\n","0_0_durAOI1 0_1_durAOI2  2777.0518  0.001  2275.6274  3278.4762   True\n","0_0_durAOI1 0_1_durAOI3  3159.4746  0.001  2658.0502   3660.899   True\n","0_0_durAOI1 0_1_durAOI4   1207.984  0.001   706.5596  1709.4084   True\n","0_0_durAOI1 0_1_durAOI5   700.4776  0.001   199.0531   1201.902   True\n","0_0_durAOI1 1_0_durAOI1    15.2596    0.9  -486.1648    516.684  False\n","0_0_durAOI1 1_0_durAOI2  5671.8882  0.001  5170.4638  6173.3126   True\n","0_0_durAOI1 1_0_durAOI3   843.4963  0.001   342.0719  1344.9207   True\n","0_0_durAOI1 1_0_durAOI4   941.5299  0.001   440.1055  1442.9544   True\n","0_0_durAOI1 1_0_durAOI5   447.2482 0.1535   -54.1763   948.6726  False\n","0_0_durAOI1 1_1_durAOI1    95.2354    0.9  -406.1891   596.6598  False\n","0_0_durAOI1 1_1_durAOI2  5515.2588  0.001  5013.8344  6016.6833   True\n","0_0_durAOI1 1_1_durAOI3  1000.2063  0.001   498.7819  1501.6307   True\n","0_0_durAOI1 1_1_durAOI4   652.0643  0.001   150.6399  1153.4887   True\n","0_0_durAOI1 1_1_durAOI5   650.9859  0.001   149.5615  1152.4103   True\n","0_0_durAOI2 0_0_durAOI3 -1468.9862  0.001 -1970.4106  -967.5618   True\n","0_0_durAOI2 0_0_durAOI4 -2163.3045  0.001 -2664.7289 -1661.8801   True\n","0_0_durAOI2 0_0_durAOI5  -3182.044  0.001 -3683.4684 -2680.6196   True\n","0_0_durAOI2 0_1_durAOI1 -3616.8298  0.001 -4118.2543 -3115.4054   True\n","0_0_durAOI2 0_1_durAOI2   -911.931  0.001 -1413.3555  -410.5066   True\n","0_0_durAOI2 0_1_durAOI3  -529.5083 0.0256 -1030.9327   -28.0839   True\n","0_0_durAOI2 0_1_durAOI4 -2480.9989  0.001 -2982.4233 -1979.5745   True\n","0_0_durAOI2 0_1_durAOI5 -2988.5053  0.001 -3489.9297 -2487.0809   True\n","0_0_durAOI2 1_0_durAOI1 -3673.7233  0.001 -4175.1477 -3172.2989   True\n","0_0_durAOI2 1_0_durAOI2  1982.9053  0.001  1481.4809  2484.3298   True\n","0_0_durAOI2 1_0_durAOI3 -2845.4866  0.001  -3346.911 -2344.0622   True\n","0_0_durAOI2 1_0_durAOI4 -2747.4529  0.001 -3248.8773 -2246.0285   True\n","0_0_durAOI2 1_0_durAOI5 -3241.7347  0.001 -3743.1591 -2740.3103   True\n","0_0_durAOI2 1_1_durAOI1 -3593.7475  0.001 -4095.1719 -3092.3231   True\n","0_0_durAOI2 1_1_durAOI2   1826.276  0.001  1324.8516  2327.7004   True\n","0_0_durAOI2 1_1_durAOI3 -2688.7766  0.001  -3190.201 -2187.3522   True\n","0_0_durAOI2 1_1_durAOI4 -3036.9186  0.001  -3538.343 -2535.4941   True\n","0_0_durAOI2 1_1_durAOI5  -3037.997  0.001 -3539.4214 -2536.5726   True\n","0_0_durAOI3 0_0_durAOI4  -694.3183  0.001 -1195.7427  -192.8939   True\n","0_0_durAOI3 0_0_durAOI5 -1713.0578  0.001 -2214.4822 -1211.6334   True\n","0_0_durAOI3 0_1_durAOI1 -2147.8437  0.001 -2649.2681 -1646.4192   True\n","0_0_durAOI3 0_1_durAOI2   557.0551 0.0126    55.6307  1058.4796   True\n","0_0_durAOI3 0_1_durAOI3   939.4779  0.001   438.0535  1440.9023   True\n","0_0_durAOI3 0_1_durAOI4 -1012.0127  0.001 -1513.4371  -510.5883   True\n","0_0_durAOI3 0_1_durAOI5 -1519.5191  0.001 -2020.9436 -1018.0947   True\n","0_0_durAOI3 1_0_durAOI1 -2204.7371  0.001 -2706.1615 -1703.3127   True\n","0_0_durAOI3 1_0_durAOI2  3451.8915  0.001  2950.4671  3953.3159   True\n","0_0_durAOI3 1_0_durAOI3 -1376.5004  0.001 -1877.9248   -875.076   True\n","0_0_durAOI3 1_0_durAOI4 -1278.4668  0.001 -1779.8912  -777.0423   True\n","0_0_durAOI3 1_0_durAOI5 -1772.7485  0.001  -2274.173 -1271.3241   True\n","0_0_durAOI3 1_1_durAOI1 -2124.7613  0.001 -2626.1858 -1623.3369   True\n","0_0_durAOI3 1_1_durAOI2  3295.2621  0.001  2793.8377  3796.6866   True\n","0_0_durAOI3 1_1_durAOI3 -1219.7904  0.001 -1721.2148   -718.366   True\n","0_0_durAOI3 1_1_durAOI4 -1567.9324  0.001 -2069.3568  -1066.508   True\n","0_0_durAOI3 1_1_durAOI5 -1569.0108  0.001 -2070.4352 -1067.5864   True\n","0_0_durAOI4 0_0_durAOI5 -1018.7395  0.001 -1520.1639  -517.3151   True\n","0_0_durAOI4 0_1_durAOI1 -1453.5253  0.001 -1954.9498  -952.1009   True\n","0_0_durAOI4 0_1_durAOI2  1251.3735  0.001    749.949  1752.7979   True\n","0_0_durAOI4 0_1_durAOI3  1633.7962  0.001  1132.3718  2135.2206   True\n","0_0_durAOI4 0_1_durAOI4  -317.6944 0.7323  -819.1188     183.73  False\n","0_0_durAOI4 0_1_durAOI5  -825.2008  0.001 -1326.6252  -323.7764   True\n","0_0_durAOI4 1_0_durAOI1 -1510.4188  0.001 -2011.8432 -1008.9944   True\n","0_0_durAOI4 1_0_durAOI2  4146.2098  0.001  3644.7854  4647.6342   True\n","0_0_durAOI4 1_0_durAOI3  -682.1821  0.001 -1183.6065  -180.7577   True\n","0_0_durAOI4 1_0_durAOI4  -584.1484  0.006 -1085.5729    -82.724   True\n","0_0_durAOI4 1_0_durAOI5 -1078.4302  0.001 -1579.8546  -577.0058   True\n","0_0_durAOI4 1_1_durAOI1  -1430.443  0.001 -1931.8674  -929.0186   True\n","0_0_durAOI4 1_1_durAOI2  3989.5805  0.001   3488.156  4491.0049   True\n","0_0_durAOI4 1_1_durAOI3  -525.4721 0.0283 -1026.8965   -24.0477   True\n","0_0_durAOI4 1_1_durAOI4  -873.6141  0.001 -1375.0385  -372.1897   True\n","0_0_durAOI4 1_1_durAOI5  -874.6925  0.001 -1376.1169  -373.2681   True\n","0_0_durAOI5 0_1_durAOI1  -434.7859 0.1917  -936.2103    66.6386  False\n","0_0_durAOI5 0_1_durAOI2  2270.1129  0.001  1768.6885  2771.5374   True\n","0_0_durAOI5 0_1_durAOI3  2652.5357  0.001  2151.1113  3153.9601   True\n","0_0_durAOI5 0_1_durAOI4   701.0451  0.001   199.6207  1202.4695   True\n","0_0_durAOI5 0_1_durAOI5   193.5387    0.9  -307.8858   694.9631  False\n","0_0_durAOI5 1_0_durAOI1  -491.6793 0.0625  -993.1037     9.7451  False\n","0_0_durAOI5 1_0_durAOI2  5164.9493  0.001  4663.5249  5666.3737   True\n","0_0_durAOI5 1_0_durAOI3   336.5574 0.6445   -164.867   837.9818  False\n","0_0_durAOI5 1_0_durAOI4   434.5911 0.1923   -66.8334   936.0155  False\n","0_0_durAOI5 1_0_durAOI5   -59.6907    0.9  -561.1151   441.7337  False\n","0_0_durAOI5 1_1_durAOI1  -411.7035 0.2802  -913.1279    89.7209  False\n","0_0_durAOI5 1_1_durAOI2    5008.32  0.001  4506.8955  5509.7444   True\n","0_0_durAOI5 1_1_durAOI3   493.2674 0.0603     -8.157   994.6918  False\n","0_0_durAOI5 1_1_durAOI4   145.1254    0.9   -356.299   646.5498  False\n","0_0_durAOI5 1_1_durAOI5    144.047    0.9  -357.3774   645.4714  False\n","0_1_durAOI1 0_1_durAOI2  2704.8988  0.001  2203.4744  3206.3232   True\n","0_1_durAOI1 0_1_durAOI3  3087.3215  0.001  2585.8971   3588.746   True\n","0_1_durAOI1 0_1_durAOI4  1135.8309  0.001   634.4065  1637.2554   True\n","0_1_durAOI1 0_1_durAOI5   628.3245 0.0016   126.9001  1129.7489   True\n","0_1_durAOI1 1_0_durAOI1   -56.8935    0.9  -558.3179    444.531  False\n","0_1_durAOI1 1_0_durAOI2  5599.7352  0.001  5098.3108  6101.1596   True\n","0_1_durAOI1 1_0_durAOI3   771.3433  0.001   269.9188  1272.7677   True\n","0_1_durAOI1 1_0_durAOI4   869.3769  0.001   367.9525  1370.8013   True\n","0_1_durAOI1 1_0_durAOI5   375.0951 0.4636  -126.3293   876.5195  False\n","0_1_durAOI1 1_1_durAOI1    23.0823    0.9  -478.3421   524.5067  False\n","0_1_durAOI1 1_1_durAOI2  5443.1058  0.001  4941.6814  5944.5302   True\n","0_1_durAOI1 1_1_durAOI3   928.0533  0.001   426.6288  1429.4777   True\n","0_1_durAOI1 1_1_durAOI4   579.9113 0.0068    78.4868  1081.3357   True\n","0_1_durAOI1 1_1_durAOI5   578.8329  0.007    77.4084  1080.2573   True\n","0_1_durAOI2 0_1_durAOI3   382.4227 0.4254  -119.0017   883.8472  False\n","0_1_durAOI2 0_1_durAOI4 -1569.0679  0.001 -2070.4923 -1067.6434   True\n","0_1_durAOI2 0_1_durAOI5 -2076.5743  0.001 -2577.9987 -1575.1499   True\n","0_1_durAOI2 1_0_durAOI1 -2761.7923  0.001 -3263.2167 -2260.3678   True\n","0_1_durAOI2 1_0_durAOI2  2894.8364  0.001   2393.412  3396.2608   True\n","0_1_durAOI2 1_0_durAOI3 -1933.5555  0.001   -2434.98 -1432.1311   True\n","0_1_durAOI2 1_0_durAOI4 -1835.5219  0.001 -2336.9463 -1334.0975   True\n","0_1_durAOI2 1_0_durAOI5 -2329.8037  0.001 -2831.2281 -1828.3793   True\n","0_1_durAOI2 1_1_durAOI1 -2681.8165  0.001 -3183.2409 -2180.3921   True\n","0_1_durAOI2 1_1_durAOI2   2738.207  0.001  2236.7826  3239.6314   True\n","0_1_durAOI2 1_1_durAOI3 -1776.8455  0.001   -2278.27 -1275.4211   True\n","0_1_durAOI2 1_1_durAOI4 -2124.9875  0.001 -2626.4119 -1623.5631   True\n","0_1_durAOI2 1_1_durAOI5 -2126.0659  0.001 -2627.4904 -1624.6415   True\n","0_1_durAOI3 0_1_durAOI4 -1951.4906  0.001  -2452.915 -1450.0662   True\n","0_1_durAOI3 0_1_durAOI5  -2458.997  0.001 -2960.4214 -1957.5726   True\n","0_1_durAOI3 1_0_durAOI1  -3144.215  0.001 -3645.6394 -2642.7906   True\n","0_1_durAOI3 1_0_durAOI2  2512.4136  0.001  2010.9892  3013.8381   True\n","0_1_durAOI3 1_0_durAOI3 -2315.9783  0.001 -2817.4027 -1814.5539   True\n","0_1_durAOI3 1_0_durAOI4 -2217.9446  0.001 -2719.3691 -1716.5202   True\n","0_1_durAOI3 1_0_durAOI5 -2712.2264  0.001 -3213.6508  -2210.802   True\n","0_1_durAOI3 1_1_durAOI1 -3064.2392  0.001 -3565.6636 -2562.8148   True\n","0_1_durAOI3 1_1_durAOI2  2355.7843  0.001  1854.3599  2857.2087   True\n","0_1_durAOI3 1_1_durAOI3 -2159.2683  0.001 -2660.6927 -1657.8439   True\n","0_1_durAOI3 1_1_durAOI4 -2507.4103  0.001 -3008.8347 -2005.9859   True\n","0_1_durAOI3 1_1_durAOI5 -2508.4887  0.001 -3009.9131 -2007.0643   True\n","0_1_durAOI4 0_1_durAOI5  -507.5064 0.0436 -1008.9308     -6.082   True\n","0_1_durAOI4 1_0_durAOI1 -1192.7244  0.001 -1694.1488     -691.3   True\n","0_1_durAOI4 1_0_durAOI2  4463.9042  0.001  3962.4798  4965.3286   True\n","0_1_durAOI4 1_0_durAOI3  -364.4877 0.5146  -865.9121   136.9367  False\n","0_1_durAOI4 1_0_durAOI4   -266.454    0.9  -767.8785   234.9704  False\n","0_1_durAOI4 1_0_durAOI5  -760.7358  0.001 -1262.1602  -259.3114   True\n","0_1_durAOI4 1_1_durAOI1 -1112.7486  0.001  -1614.173  -611.3242   True\n","0_1_durAOI4 1_1_durAOI2  4307.2749  0.001  3805.8504  4808.6993   True\n","0_1_durAOI4 1_1_durAOI3  -207.7777    0.9  -709.2021   293.6467  False\n","0_1_durAOI4 1_1_durAOI4  -555.9197  0.013 -1057.3441   -54.4953   True\n","0_1_durAOI4 1_1_durAOI5  -556.9981 0.0126 -1058.4225   -55.5737   True\n","0_1_durAOI5 1_0_durAOI1   -685.218  0.001 -1186.6424  -183.7936   True\n","0_1_durAOI5 1_0_durAOI2  4971.4107  0.001  4469.9862  5472.8351   True\n","0_1_durAOI5 1_0_durAOI3   143.0187    0.9  -358.4057   644.4432  False\n","0_1_durAOI5 1_0_durAOI4   241.0524    0.9   -260.372   742.4768  False\n","0_1_durAOI5 1_0_durAOI5  -253.2294    0.9  -754.6538    248.195  False\n","0_1_durAOI5 1_1_durAOI1  -605.2422 0.0032 -1106.6666  -103.8178   True\n","0_1_durAOI5 1_1_durAOI2  4814.7813  0.001  4313.3569  5316.2057   True\n","0_1_durAOI5 1_1_durAOI3   299.7287 0.8158  -201.6957   801.1532  False\n","0_1_durAOI5 1_1_durAOI4   -48.4133    0.9  -549.8377   453.0112  False\n","0_1_durAOI5 1_1_durAOI5   -49.4917    0.9  -550.9161   451.9328  False\n","1_0_durAOI1 1_0_durAOI2  5656.6286  0.001  5155.2042  6158.0531   True\n","1_0_durAOI1 1_0_durAOI3   828.2367  0.001   326.8123  1329.6611   True\n","1_0_durAOI1 1_0_durAOI4   926.2704  0.001   424.8459  1427.6948   True\n","1_0_durAOI1 1_0_durAOI5   431.9886 0.2013   -69.4358    933.413  False\n","1_0_durAOI1 1_1_durAOI1    79.9758    0.9  -421.4486   581.4002  False\n","1_0_durAOI1 1_1_durAOI2  5499.9993  0.001  4998.5749  6001.4237   True\n","1_0_durAOI1 1_1_durAOI3   984.9467  0.001   483.5223  1486.3711   True\n","1_0_durAOI1 1_1_durAOI4   636.8047 0.0012   135.3803  1138.2291   True\n","1_0_durAOI1 1_1_durAOI5   635.7263 0.0013   134.3019  1137.1507   True\n","1_0_durAOI2 1_0_durAOI3 -4828.3919  0.001 -5329.8163 -4326.9675   True\n","1_0_durAOI2 1_0_durAOI4 -4730.3583  0.001 -5231.7827 -4228.9339   True\n","1_0_durAOI2 1_0_durAOI5 -5224.6401  0.001 -5726.0645 -4723.2156   True\n","1_0_durAOI2 1_1_durAOI1 -5576.6528  0.001 -6078.0773 -5075.2284   True\n","1_0_durAOI2 1_1_durAOI2  -156.6294    0.9  -658.0538   344.7951  False\n","1_0_durAOI2 1_1_durAOI3 -4671.6819  0.001 -5173.1063 -4170.2575   True\n","1_0_durAOI2 1_1_durAOI4 -5019.8239  0.001 -5521.2483 -4518.3995   True\n","1_0_durAOI2 1_1_durAOI5 -5020.9023  0.001 -5522.3267 -4519.4779   True\n","1_0_durAOI3 1_0_durAOI4    98.0336    0.9  -403.3908   599.4581  False\n","1_0_durAOI3 1_0_durAOI5  -396.2481 0.3519  -897.6726   105.1763  False\n","1_0_durAOI3 1_1_durAOI1  -748.2609  0.001 -1249.6854  -246.8365   True\n","1_0_durAOI3 1_1_durAOI2  4671.7625  0.001  4170.3381   5173.187   True\n","1_0_durAOI3 1_1_durAOI3     156.71    0.9  -344.7144   658.1344  False\n","1_0_durAOI3 1_1_durAOI4   -191.432    0.9  -692.8564   309.9924  False\n","1_0_durAOI3 1_1_durAOI5  -192.5104    0.9  -693.9348    308.914  False\n","1_0_durAOI4 1_0_durAOI5  -494.2818  0.059  -995.7062     7.1426  False\n","1_0_durAOI4 1_1_durAOI1  -846.2946  0.001  -1347.719  -344.8702   True\n","1_0_durAOI4 1_1_durAOI2  4573.7289  0.001  4072.3045  5075.1533   True\n","1_0_durAOI4 1_1_durAOI3    58.6764    0.9  -442.7481   560.1008  False\n","1_0_durAOI4 1_1_durAOI4  -289.4656 0.8635  -790.8901   211.9588  False\n","1_0_durAOI4 1_1_durAOI5  -290.5441 0.8585  -791.9685   210.8804  False\n","1_0_durAOI5 1_1_durAOI1  -352.0128 0.5726  -853.4372   149.4116  False\n","1_0_durAOI5 1_1_durAOI2  5068.0107  0.001  4566.5863  5569.4351   True\n","1_0_durAOI5 1_1_durAOI3   552.9581 0.0141    51.5337  1054.3825   True\n","1_0_durAOI5 1_1_durAOI4   204.8161    0.9  -296.6083   706.2406  False\n","1_0_durAOI5 1_1_durAOI5   203.7377    0.9  -297.6867   705.1621  False\n","1_1_durAOI1 1_1_durAOI2  5420.0235  0.001  4918.5991  5921.4479   True\n","1_1_durAOI1 1_1_durAOI3   904.9709  0.001   403.5465  1406.3953   True\n","1_1_durAOI1 1_1_durAOI4   556.8289 0.0127    55.4045  1058.2534   True\n","1_1_durAOI1 1_1_durAOI5   555.7505 0.0131    54.3261  1057.1749   True\n","1_1_durAOI2 1_1_durAOI3 -4515.0526  0.001  -5016.477 -4013.6281   True\n","1_1_durAOI2 1_1_durAOI4 -4863.1945  0.001  -5364.619 -4361.7701   True\n","1_1_durAOI2 1_1_durAOI5  -4864.273  0.001 -5365.6974 -4362.8485   True\n","1_1_durAOI3 1_1_durAOI4   -348.142 0.5906  -849.5664   153.2824  False\n","1_1_durAOI3 1_1_durAOI5  -349.2204 0.5856  -850.6448    152.204  False\n","1_1_durAOI4 1_1_durAOI5    -1.0784    0.9  -502.5028    500.346  False\n","----------------------------------------------------------------------\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["import pandas as pd\n","import numpy as np\n","import scipy.stats as stats\n","import statsmodels.api as sm\n","from statsmodels.formula.api import ols\n","from statsmodels.stats.anova import anova_lm\n","from statsmodels.stats.anova import AnovaRM\n","from statsmodels.graphics.factorplots import interaction_plot\n","from statsmodels.stats.multicomp import MultiComparison, pairwise_tukeyhsd, tukeyhsd\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as mpatches\n","import seaborn as sns\n","\n","#########################\n","# Importing data\n","dfaveraged_data = pd.read_csv('./data/averagedPMPVmode_w10_data.csv')\n","#########################\n","# Creating groups \"mode x label\" for multiple comparison purposes \n","dfaveraged_data['modeperf'] = dfaveraged_data['mode'].map(str) + dfaveraged_data['label'].map(str)\n","dfaveraged_data['submission'] = dfaveraged_data['subject'].map(str) + \"_\" + dfaveraged_data['mission'].map(str)\n","print(dfaveraged_data.columns)\n","\n","#########################\n","# EXAMPLE \n","# ANOVA considering performance group and robot operation mode\n","# NOTE: we have to assume that each mission is independent here because \n","# some participants belong only to one performance group\n","# (in reality intra-subject sample are dependent)\n","\n","# 1) We try to verify the hypothesis :\n","# H0 : HRV is not impacted by the operation mode nor the performance group (label)\n","# H1 : HRV is impacted by the operation mode or the performance group (label)\n","print(\"#####################################################################\")\n","print(\"2-WAY ANOVA H1: HRV is impacted by the operation mode and the performance (label)\")\n","HRVmodel = ols('HRV ~ C(mode)*C(label)', dfaveraged_data).fit()\n","print(f\"Overall model F({HRVmodel.df_model: .0f},{HRVmodel.df_resid: .0f}) = {HRVmodel.fvalue: .3f}, p = {HRVmodel.f_pvalue: .4f}\")\n","print()\n","print(HRVmodel.summary())\n","res = sm.stats.anova_lm(HRVmodel, typ= 2)\n","print()\n","print(res)\n","\n","# perform multiple comparison (post-hoc Tukey HSD)\n","m_comp = MultiComparison(dfaveraged_data['HRV'], groups=dfaveraged_data['modeperf']).tukeyhsd(alpha=0.05)\n","print(m_comp)\n","\n","##################################################\n","### PLEASE DO THE SAME ANALYSIS WITH HR JUST BELOW\n","\n","# H0 : HR is not impacted by the operation mode nor the performance group (label)\n","# H1 : HR is impacted by the operation mode or the performance group (label)\n","print(\"#####################################################################\")\n","print(\"2-WAY ANOVA H1: HR is impacted by the operation mode and the performance (label)\")\n","HRmodel = ols('HR ~ C(mode)*C(label)', dfaveraged_data).fit()\n","print(f\"Overall model F({HRmodel.df_model: .0f},{HRmodel.df_resid: .0f}) = {HRmodel.fvalue: .3f}, p = {HRmodel.f_pvalue: .4f}\")\n","print()\n","print(HRmodel.summary())\n","res1 = sm.stats.anova_lm(HRmodel, typ= 2)\n","print()\n","print(res1)\n","\n","# perform multiple comparison (post-hoc Tukey HSD)\n","m_comp1 = MultiComparison(dfaveraged_data['HR'], groups=dfaveraged_data['modeperf']).tukeyhsd(alpha=0.05)\n","print(m_comp1)\n","\n","\n","\n","#################################################################\n","### NOW LET'S ANALYSE THE NUMBER OF FIXATIONS IN AOIs (nbFixAOIX)\n","# for instance:\n","# 2a) We try to verify the hypothesis : \n","# H0 : the number of fixations is not affected by the AOI index nor the operation mode\n","# H1 : the number of fixations is affected by the AOI index or the operation mode\n","df = pd.melt(dfaveraged_data[[\"modeperf\",\"mode\",\"label\",\"submission\",\"subject\",\"nbAOI1\",\"nbAOI2\",\"nbAOI3\",\"nbAOI4\",\"nbAOI5\"]], \n","             id_vars=[\"modeperf\",\"submission\",\"mode\",\"label\",\"subject\"], \n","             value_vars=[\"nbAOI1\",\"nbAOI2\",\"nbAOI3\",\"nbAOI4\",\"nbAOI5\"])\n","df = df.rename(columns={'value': 'nbFix'})\n","df = df.rename(columns={'variable': 'AOI'})\n","\n","# NOTE: we use a repeated measures ANOVA design because data is dependent within subjects and missions\n","res=AnovaRM(data=df,depvar=\"nbFix\",subject=\"submission\", within=[\"AOI\",\"mode\"]).fit()\n","print(res)\n","\n","# 2b) We try to verify the hypothesis : \n","# H0 : the number of fixations is not affected by the AOI index nor the operation mode nor the performance label\n","# H1 : the number of fixations is affected by the AOI index or the operation mode or the performance label\n","# NOTE: we can't use repeated measure ANOVA design in this case because:\n","# all the conditions aren't repeated within subjects\n","sns.boxenplot(x=\"AOI\", y=\"nbFix\", hue=\"modeperf\", linewidth=1, data=df)\n","print(\"#####################################################################\")\n","print(\"3-WAY ANOVA H1: nbFix is impacted by the AOI, the operation mode and the performance (label)\")\n","nbFixModel = ols('nbFix ~ C(mode)*C(label)*C(AOI)', df).fit()\n","res = sm.stats.anova_lm(nbFixModel, typ= 3)\n","print(res)\n","\n","# perform multiple comparison (post-hoc Tukey HSD)\n","df['modeperfAOI'] = df['mode'].map(str) + \"_\" + df['label'].map(str) + \"_\" + df['AOI'].map(str)\n","m_comp_crossAOIs = MultiComparison(df['nbFix'], groups=df['modeperfAOI']).tukeyhsd(alpha=0.05)\n","print(m_comp_crossAOIs)\n","plt.show()\n","\n","###########################################################################\n","### PLEASE DO THE SAME ANALYSIS WITH THE AOIs FIXATION DURATIONS JUST BELOW\n","\n","# 3a) We try to verify the hypothesis : \n","# H0 : the AOIs fixation duration is not affected by the AOI index nor the operation mode\n","# H1 : the AOIs fixation duration is affected by the AOI index or the operation mode\n","df1 = pd.melt(dfaveraged_data[[\"modeperf\",\"mode\",\"label\",\"submission\",\"subject\",\"durAOI1\",\"durAOI2\",\"durAOI3\",\"durAOI4\",\"durAOI5\"]], \n","             id_vars=[\"modeperf\",\"submission\",\"mode\",\"label\",\"subject\"], \n","             value_vars=[\"durAOI1\",\"durAOI2\",\"durAOI3\",\"durAOI4\",\"durAOI5\"])\n","df1 = df1.rename(columns={'value': 'durFix'})\n","df1 = df1.rename(columns={'variable': 'AOI'})\n","\n","# NOTE: we use a repeated measures ANOVA design because data is dependent within subjects and missions\n","res2=AnovaRM(data=df1,depvar=\"durFix\",subject=\"submission\", within=[\"AOI\",\"mode\"]).fit()\n","print(res2)\n","\n","# 3b) We try to verify the hypothesis : \n","# H0 : the number of fixations is not affected by the AOI index nor the operation mode nor the performance label\n","# H1 : the number of fixations is affected by the AOI index or the operation mode or the performance label\n","# NOTE: we can't use repeated measure ANOVA design in this case because:\n","# all the conditions aren't repeated within subjects\n","sns.boxenplot(x=\"AOI\", y=\"durFix\", hue=\"modeperf\", linewidth=1, data=df1)\n","print(\"#####################################################################\")\n","print(\"3-WAY ANOVA H1: durFix is impacted by the AOI, the operation mode and the performance (label)\")\n","durFixModel = ols('durFix ~ C(mode)*C(label)*C(AOI)', df1).fit()\n","res2 = sm.stats.anova_lm(durFixModel, typ= 3)\n","print(res2)\n","\n","# perform multiple comparison (post-hoc Tukey HSD)\n","df1['modeperfAOI'] = df1['mode'].map(str) + \"_\" + df1['label'].map(str) + \"_\" + df1['AOI'].map(str)\n","m_comp_crossAOIs2 = MultiComparison(df1['durFix'], groups=df1['modeperfAOI']).tukeyhsd(alpha=0.05)\n","print(m_comp_crossAOIs2)\n","plt.show()\n","\n","\n","####################################################################################\n","### PLEASE DO THE SAME ANALYSIS WITH THE KEYSTROKES AND CLICKS (nav,tank) JUST BELOW\n","\n","## plotting operation mode x nav keystrokes grouped by the performance label\n","plotting_data_per_perfgroup(dfaveraged_data, \"mode\", \"nav\")\n","plt.show()\n","#plt.clf()\n","\n","## plotting operation mode x tank keystrokes grouped by the performance label\n","plotting_data_per_perfgroup(dfaveraged_data, \"mode\", \"tank\")\n","plt.show()\n","#plt.clf()\n"]},{"cell_type":"markdown","metadata":{"id":"bExY2qsUJvb8"},"source":["#### Draw your conclusions for the task 1.1.2 here:"]},{"cell_type":"markdown","metadata":{"id":"3jKQjqeUJvb8"},"source":["Answer: Lors de la question précédente, nous avions déjà remarqué que les marqueurs nav, nbAOI1, nbAOI3 et nbAOI5 étaient impactés par la performance du joueur. L'analyse ci-dessus nous permet de déterminer en plus dans quelle mesure les durées de fixation sur les AOIs sont impactées par la performance du joueur.\n","Ainsi, les durées de fixation sur les AOI2 et AOI3 sont impactés par les performances du joueur."]},{"cell_type":"markdown","metadata":{"id":"IaUevkKXJvb8"},"source":["**Task 1.1.3: Based on the results obtained above, define the subdataset to be considered for classification**\n","\n","**Remark 1 :** note that the data file *df10labeled_data* will be used in this exercise, where all 10-second time windows are listed. The goal here is to produce a prediction for each sample built on a 10-second time window"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QMVkWEnGJvb9","outputId":"8be62b26-8c91-4e71-eafe-d466d66b7ebb"},"outputs":[{"name":"stdout","output_type":"stream","text":["      subject  mission  mode         HR       HRV   nav  tank  space  trees  \\\n","0        19.0      1.0   0.0  72.568940 -0.066819  14.0   0.0    0.0    0.0   \n","1        19.0      1.0   0.0  74.229865 -0.087446  18.0   2.0    0.0    0.0   \n","2        19.0      1.0   1.0  73.304826 -0.070724   9.0   5.0    0.0    0.0   \n","3        19.0      1.0   1.0  69.962687 -0.050697   0.0   8.0    0.0    0.0   \n","4        19.0      1.0   1.0  70.771408 -0.076950   0.0   7.0    0.0    1.0   \n","...       ...      ...   ...        ...       ...   ...   ...    ...    ...   \n","3586     40.0      4.0   1.0  69.767442 -0.041904   0.0  24.0    0.0    0.0   \n","3587     40.0      4.0   0.0  67.046597 -0.043276  12.0   8.0    0.0    0.0   \n","3588     40.0      4.0   0.0  69.549090 -0.044936  10.0  14.0    0.0    0.0   \n","3589     40.0      4.0   0.0  72.245635 -0.045260   6.0   8.0    1.0    0.0   \n","3590     40.0      4.0   1.0  71.564885 -0.048838   2.0   9.0    0.0    0.0   \n","\n","      nbAOI1  ...  nbAOI4  nbAOI5  durAOI1   durAOI2  durAOI3   durAOI4  \\\n","0        0.0  ...    17.0    13.0      0.0     0.000  396.012  4315.727   \n","1        0.0  ...    14.0     8.0      0.0   799.830  616.039  5164.160   \n","2        0.0  ...     6.0     2.0      0.0  4567.621  323.665  1076.000   \n","3        0.0  ...     2.0     0.0      0.0  8334.850  507.983   404.020   \n","4        0.0  ...     0.0     4.0      0.0  6839.057  288.020     0.000   \n","...      ...  ...     ...     ...      ...       ...      ...       ...   \n","3586     0.0  ...     5.0     2.0      0.0  8130.931    0.000   843.695   \n","3587     0.0  ...    10.0     3.0      0.0  3607.340    0.000  3371.289   \n","3588     0.0  ...    15.0     1.0      0.0  4155.458    0.000  4095.549   \n","3589     0.0  ...     7.0     2.0      0.0  4499.490    0.000  4619.240   \n","3590     0.0  ...    12.0     7.0      0.0  3847.525    0.000  3134.870   \n","\n","       durAOI5  tank_local_score    HRnorm  label  \n","0     2627.351             0.000  6.185203    1.0  \n","1     1296.772            -2.222  7.846128    1.0  \n","2      411.970            -8.445  6.921088    1.0  \n","3        0.000             4.555  3.578949    1.0  \n","4     1471.901            19.032  4.387671    1.0  \n","...        ...               ...       ...    ...  \n","3586   339.979             7.286  3.992174    0.0  \n","3587  1307.800             2.714  1.271330    0.0  \n","3588   156.010             3.778  3.773822    0.0  \n","3589   415.880            -0.334  6.470367    0.0  \n","3590  1252.000            -1.111  5.789618    0.0  \n","\n","[3591 rows x 22 columns]\n","      subject  mission  mode         HR       HRV   nav  tank  space  trees  \\\n","232      20.0      1.0   0.0  81.753995 -0.024002   0.0   6.0    0.0    0.0   \n","233      20.0      1.0   1.0  81.212777 -0.022410  37.0   1.0    0.0    0.0   \n","234      20.0      1.0   1.0  82.259391 -0.013181   1.0   8.0    0.0    1.0   \n","235      20.0      1.0   1.0  85.506627 -0.017608   0.0   7.0    0.0    1.0   \n","236      20.0      1.0   0.0  86.767896 -0.024006  19.0   6.0    0.0    0.0   \n","...       ...      ...   ...        ...       ...   ...   ...    ...    ...   \n","3500     39.0      4.0   1.0  83.437630 -0.090905   0.0  20.0    0.0    0.0   \n","3501     39.0      4.0   0.0  79.498916 -0.071000  27.0   0.0    2.0    2.0   \n","3502     39.0      4.0   1.0  78.328982 -0.039412   6.0   0.0    0.0    0.0   \n","3503     39.0      4.0   0.0  91.486658 -0.034352  33.0   0.0    0.0    0.0   \n","3504     39.0      4.0   1.0  85.514382 -0.021361   4.0   0.0    0.0    0.0   \n","\n","      nbAOI1  ...  nbAOI4  nbAOI5  durAOI1   durAOI2   durAOI3   durAOI4  \\\n","232      0.0  ...     3.0     0.0    0.000  5270.240   267.980  1203.800   \n","233      0.0  ...     7.0     0.0    0.000  1147.790  5415.409  3251.690   \n","234      0.0  ...     4.0     4.0    0.000  6031.067   947.860   819.810   \n","235      0.0  ...     7.0     3.0    0.000  6143.030   471.870  1899.458   \n","236      0.0  ...     8.0     4.0    0.000  5603.170  1111.940  2219.590   \n","...      ...  ...     ...     ...      ...       ...       ...       ...   \n","3500     4.0  ...     8.0     2.0  639.975  5383.590   531.880  1651.611   \n","3501     6.0  ...     6.0     0.0  812.020   172.000  6643.306   975.864   \n","3502     2.0  ...    21.0     6.0  356.020   764.020  2107.815  4007.739   \n","3503     5.0  ...     6.0     7.0  923.933   587.890  4227.799  1507.870   \n","3504     0.0  ...     8.0     4.0    0.000  1323.856  3195.732  1795.872   \n","\n","       durAOI5  tank_local_score     HRnorm  label  \n","232      0.000            14.571   1.744660    0.0  \n","233      0.000             9.207   1.203443    0.0  \n","234    859.840            -2.000   2.250057    0.0  \n","235    635.950            12.858   5.497292    0.0  \n","236    587.960             4.230   6.758561    0.0  \n","...        ...               ...        ...    ...  \n","3500   275.990             6.611  13.290321    1.0  \n","3501     0.000             0.000   9.351607    1.0  \n","3502  1192.038            -2.333   8.181672    1.0  \n","3503   939.931            -4.445  21.339349    1.0  \n","3504   699.990            -4.444  15.367073    1.0  \n","\n","[2797 rows x 22 columns]\n","       nav  nbAOI1  nbAOI3  nbAOI5   durAOI2   durAOI3  label\n","232    0.0     0.0     1.0     0.0  5270.240   267.980    0.0\n","233   37.0     0.0    17.0     0.0  1147.790  5415.409    0.0\n","234    1.0     0.0     4.0     4.0  6031.067   947.860    0.0\n","235    0.0     0.0     3.0     3.0  6143.030   471.870    0.0\n","236   19.0     0.0     4.0     4.0  5603.170  1111.940    0.0\n","...    ...     ...     ...     ...       ...       ...    ...\n","3500   0.0     4.0     2.0     2.0  5383.590   531.880    1.0\n","3501  27.0     6.0    25.0     0.0   172.000  6643.306    1.0\n","3502   6.0     2.0    11.0     6.0   764.020  2107.815    1.0\n","3503  33.0     5.0    21.0     7.0   587.890  4227.799    1.0\n","3504   4.0     0.0    15.0     4.0  1323.856  3195.732    1.0\n","\n","[2797 rows x 7 columns]\n"]}],"source":["import pandas as pd\n","import numpy as np\n","\n","#########################################################\n","# importing data\n","df10labeled_data = pd.read_csv('./data/df10labeled_data.csv')\n","print(df10labeled_data)\n","\n","#########################################################\n","## Next, we propose to remove  data samples related to some subjects from the training data set:\n","## note that it allows to verify that the framework is working with new subjects never used for \n","## learning POMDP parameters.\n","\n","## EXAMPLE: we exclude here subjects 19, 23, 33 and 38\n","subdf10labeled_data = df10labeled_data.loc[(df10labeled_data[\"subject\"]!=19)&\n","                                           (df10labeled_data[\"subject\"]!=23)&\n","                                           (df10labeled_data[\"subject\"]!=33)&\n","                                           (df10labeled_data[\"subject\"]!=40)]\n","print(subdf10labeled_data)\n","\n","##########################################################\n","## EXAMPLE of feature selection \n","## please select features according to your previous statistical analysis !!\n","subdataset = subdf10labeled_data.loc[:, ['nav',  \n","                                      'nbAOI1',  \n","                                      'nbAOI3',  \n","                                      'nbAOI5',\n","                                      'durAOI2',\n","                                      'durAOI3',   \n","                                      'label']]\n","\n","print(subdataset)"]},{"cell_type":"markdown","metadata":{"id":"X_d49UwzJvb9"},"source":["**Task 1.1.4 Classifier Setup**\n","\n","The goal here is to find the best classifier (i.e. the most accurate) to predict the human operator's mental state.\n","\n","Thus, we propose to:\n","1. split the dataset into training and testing sets\n","2. choose a classifier according to the sklearn map (https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)\n","2. define a pipeline (https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)\n","3. select the hyper-paremeters to be cross-validated as well as the associated candidates for each hyper-parameter\n","4. define the grid-search cross-validation classifier\n","5. train it using the fit method on the training set\n","6. evaluate the resulting classifier on the testing set\n","7. go back to step 2\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w8Nh_CnqJvb9","outputId":"50bfa8df-f549-432e-aba8-621d60bcdd16"},"outputs":[{"name":"stdout","output_type":"stream","text":["Available meta-parameters:  dict_keys(['algorithm', 'base_estimator', 'learning_rate', 'n_estimators', 'random_state'])\n","Best parameters:  {'n_estimators': 15}\n","Score 3 opt:  0.7091139158366049\n","              precision    recall  f1-score   support\n","\n","         0.0       0.65      0.52      0.58       490\n","         1.0       0.68      0.78      0.73       629\n","\n","    accuracy                           0.67      1119\n","   macro avg       0.66      0.65      0.65      1119\n","weighted avg       0.67      0.67      0.66      1119\n","\n"]}],"source":["#### PLEASE PUT YOUR CODE HERE\n","\n","### import libraries\n","\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from matplotlib.pyplot import figure\n","from matplotlib.colors import ListedColormap\n","\n","from sklearn.utils import all_estimators\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.svm import SVC\n","from sklearn.gaussian_process import GaussianProcessClassifier\n","from sklearn.gaussian_process.kernels import RBF\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n","\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","\n","from sklearn.model_selection import GridSearchCV\n","#from sklearn.grid_search import GridSearchCV\n","\n","### split dataset into training and testing sets\n","\n","\n","v = subdataset.values\n","X = v[:, 0:5]\n","y = v[:,-1]\n","\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4)\n","\n","\n","\n","### define classifier\n","\n","# Nous avons entraîné trois classifieurs différents pour comparer leurs scores sur notre jeu de données. \n","# Sans optimisation des paramètres des classifieurs, adaBoost est le plus performant.\n","\n","clf1 = SVC()\n","\n","clf2 = GaussianProcessClassifier (1.0 * RBF(1.0))\n","clf3 = AdaBoostClassifier()\n","\n","#clf1.fit(X_train, y_train)\n","#clf2.fit(X_train, y_train)\n","#clf3.fit(X_train, y_train)\n","\n","#score1 = clf1.score(X_test, y_test)\n","#score2 = clf2.score(X_test, y_test)\n","#score3 = clf3.score(X_test, y_test)\n","\n","#print(\"Score SVC: \", score1)\n","#print(\"Score Gaussian: \", score2)\n","#print(\"Score Ada : \", score3)\n","\n","\n","\n","\n","####### !!!!!! Utiliser adaboost plutot que SVC qui est trop lent !!!!!!!!!!!!!!!!!!!!!!!!\n","\n","\n","### define pipeline\n","\n","### define hyper-parameters and associated candidates\n","\n","print(\"Available meta-parameters: \", clf3.get_params().keys())\n","\n","#meta_parameters = {\n","    #'kernel': ['linear', 'rbf'],\n","    #'C': [0.1,1,10]\n","#}\n","\n","meta_parameters = {#\"base_estimator\" : [\"gini\", \"entropy\"],\n","              #\"base_estimator\" :   [\"best\", \"random\"],\n","              \"n_estimators\": [1, 2,3,15,20,30]\n","             }\n","\n","opt_clf3 = GridSearchCV(clf3, meta_parameters, scoring = 'roc_auc')\n","\n","\n","\n","opt_clf3.fit(X_train, y_train)\n","print(\"Best parameters: \", opt_clf3.best_params_)\n","\n","score3opt = opt_clf3.score(X_test, y_test)\n","print(\"Score 3 opt: \", score3opt)\n","\n","### define the grid search cross-validation classifier\n","\n","\n","\n","### train using the fit method\n","\n","\n","### evaluate the classifier and print results\n","\n","from sklearn.metrics import confusion_matrix\n","y_pred = opt_clf3.predict(X_test)\n","\n","print(classification_report(y_test, y_pred))"]},{"cell_type":"markdown","metadata":{"id":"aEJUw3h6Jvb9"},"source":["**Task 1.1.5: Extract the confusion matrix of your classifier**\n","\n","**Remark 1 :** use the notions learnt in the Machine Learning introduction lecture\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"id":"QhjooC_DJvb9","outputId":"52d5ab62-3953-4dae-b9b6-9c44f2a76403"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[255 235]\n"," [137 492]]\n"]}],"source":["## Extract the confusion matrix of your classifier here\n","\n","#y_pred=y_pred[:len(y_pred)-1]\n","Mconf = confusion_matrix(y_test, y_pred)\n","print(Mconf)"]},{"cell_type":"markdown","metadata":{"id":"XYZPFqUnJvb-"},"source":["**Task 1.1.6: Based on the confusion matrix, please formalize your POMDP observation function hereafter:**\n","\n","Answer : $Pr(o' \\mid s', a) = o(a,s',o')\n","= \\begin{bmatrix} Pr(oe \\mid e) & Pr(one \\mid e) \\\\ Pr(one \\mid ne) & Pr(oe \\mid ne) \\end{bmatrix}\n","= \\begin{bmatrix} TPR & FPR \\\\ FNR & TNR \\end{bmatrix}\n","= \\begin{bmatrix} \\Phi_{00} & \\Phi_{01} \\\\ \\Phi_{10} & \\Phi_{11} \\end{bmatrix}$,\n","$\\forall a \\in A$, \n","\n","and with\n","$\\Phi_{00} = ?? $, $\\Phi_{01} = ?? $, $\\Phi_{10} = ?? $, and $\\Phi_{11} = ?? $.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KLVukcDRJvb-","outputId":"27194aff-8c49-4a5b-d9fe-57f38579673a"},"outputs":[{"data":{"text/plain":["array([[0.52040816, 0.47959184],\n","       [0.21780604, 0.78219396]])"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["tot1 = sum(Mconf[0,:])\n","tot2 = sum(Mconf[1,:])\n","\n","obsfunc = np.zeros((2,2))\n","obsfunc[0,0] = Mconf[0,0]/tot1\n","obsfunc[0,1] = Mconf[0,1]/tot1\n","obsfunc[1,0] = Mconf[1,0]/tot2\n","obsfunc[1,1] = Mconf[1,1]/tot2\n","\n","obsfunc"]},{"cell_type":"markdown","metadata":{"id":"OuSQEN2_Jvb-"},"source":["### Task 1.2 : Define the POMDP reward function\n","\n","An optimal policy maximizes the sum of rewards over time. \n","The reward function therefore defines the criterion that the artificial agent seeks to optimize. \n","Here we would like to define this reward function.\n","\n","Since the goal of the task is to put out as many fires as possible,\n","the reward should be defined as the number of tree extinguished\n","during the 10-second time window denoted by $R_t$: the value function is then:\n","\n","$ V = \\mathbb{E}\\big[ \\sum_t R_t \\big]\n","= \\mathbb{E} \\Big[ \\sum_t  \\mathbb{E} \\big[ R_t \\mid s_t, a_t \\big] \\Big]\n","= \\mathbb{E} \\Big[ \\sum_t  r(s_t, a_t) \\Big]$,\n","\n","where, $r(s,a) = \\mathbb{E} \\big[ R_t \\mid s_t=s, a_t=a \\big]$\n","is the expectation of the reward given the system state and the agent action,\n","that could be defined as the reward function.\n","\n","These expectations ($\\forall (s,a) \\in S \\times A)$ can be easily approximated using the dataset,\n","and the resulting averages can then be used to define the reward function in practice.\n","To this end, it is important to analyse again our averaged dataset. \n"]},{"cell_type":"markdown","metadata":{"id":"bv3GC-UAJvb-"},"source":["**1.2.1. Given the state and action spaces defined above, please formalize your reward function:**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"SJ3Nmo3eJvb-","outputId":"d1d7a9e5-dd59-416f-8dfe-5dd8a1cefd0a"},"outputs":[{"name":"stdout","output_type":"stream","text":["            HR       HRV     HRnorm     durAOI1      durAOI2      durAOI3  \\\n","8    82.295194 -0.011808   2.285859    9.052105  3411.254211  2662.639158   \n","9    82.833853 -0.015138   2.824519   51.800400  5984.961700  1160.086400   \n","10   82.448589 -0.011103   2.301653   52.878778  3048.446926  2957.604815   \n","11   83.831082 -0.016444   3.684146   76.739937  4791.576750  1492.667406   \n","12   84.516933 -0.027626   8.905743   93.947400  3010.153567  3175.275367   \n","..         ...       ...        ...         ...          ...          ...   \n","131  77.796189 -0.084523  12.028904  165.633828  6293.623069   984.899655   \n","132  79.965476 -0.054221  10.763638  129.986393  2800.301321  3590.642643   \n","133  80.086270 -0.048275  10.884432  242.803290  5875.506355  1322.870677   \n","134  80.606207 -0.075121  10.458897  214.454885  3352.373462  3201.969385   \n","135  80.395658 -0.063058  10.248348  109.075606  5557.652758  1190.550152   \n","\n","         durAOI4     durAOI5  mission  mode  ...     nbAOI3    nbAOI4  \\\n","8    2024.707474  651.056895        1     0  ...  10.052632  8.736842   \n","9     989.266750  761.048800        1     1  ...   4.850000  4.050000   \n","10   1981.321333  757.186222        2     0  ...  11.370370  7.148148   \n","11   1511.614812  839.359312        2     1  ...   6.281250  7.125000   \n","12   1787.026167  694.546767        3     0  ...  12.100000  7.033333   \n","..           ...         ...      ...   ...  ...        ...       ...   \n","131   902.066793  325.784862        2     1  ...   3.620690  4.655172   \n","132  1410.911286  456.077536        3     0  ...  17.464286  8.321429   \n","133   796.951097  350.282161        3     1  ...   6.064516  4.967742   \n","134  1306.153038  442.124846        4     0  ...  13.500000  6.692308   \n","135  1519.516667  379.235939        4     1  ...   5.454545  7.333333   \n","\n","       nbAOI5     space  subject       tank  tank_local_score     trees  \\\n","8    3.526316  0.631579       20   4.210526         -3.201743  0.473684   \n","9    3.400000  0.250000       20   9.600000          2.360983  0.400000   \n","10   3.555556  0.777778       20   3.518519         -2.031978  0.518519   \n","11   3.468750  0.093750       20   5.937500          0.778544  0.406250   \n","12   3.700000  0.633333       20   3.933333         -3.210790  0.533333   \n","..        ...       ...      ...        ...               ...       ...   \n","131  1.931034  0.137931       39  15.103448          5.590903  0.344828   \n","132  2.928571  0.678571       39   7.000000        -12.091624  0.678571   \n","133  2.129032  0.032258       39  15.354839          8.529877  0.451613   \n","134  2.615385  0.653846       39   6.769231         -6.795173  0.653846   \n","135  2.212121  0.121212       39  12.848485          5.819527  0.393939   \n","\n","     nbt_trees_mode  label  \n","8                 9      0  \n","9                 8      0  \n","10               14      1  \n","11               13      1  \n","12               16      1  \n","..              ...    ...  \n","131              10      1  \n","132              19      1  \n","133              14      1  \n","134              17      1  \n","135              13      1  \n","\n","[112 rows x 23 columns]\n","[[0.55484027 0.28190895]\n"," [0.41760041 0.35650864]]\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as mpatches\n","import seaborn as sns\n","\n","##################################################\n","## importing data\n","dfaveraged_data = pd.read_csv('./data/averagedPMPVmode_w10_data.csv')\n","\n","##################################################\n","## excluding the same participants as before\n","subdfaveraged_data = dfaveraged_data.loc[(dfaveraged_data[\"subject\"]!=19)&\n","                                           (dfaveraged_data[\"subject\"]!=23)&\n","                                           (dfaveraged_data[\"subject\"]!=33)&\n","                                           (dfaveraged_data[\"subject\"]!=40)]\n","print (subdfaveraged_data)\n","\n","##################################################\n","### PLEASE proceed with computations of the four (4) reward function values\n","### Remind that expectations can be easily approximated using the dataset, \n","### and the resulting averages can then be used to define the reward function in practice.\n","\n","#2 états : engagé, désengagé\n","#actions : manuel, auto\n","#fonction de reward : matrice 2*2\n","\n","\n","#Reward function\n","R = np.zeros((2,2))\n","\n","\n","mode = dfaveraged_data['mode'].tolist()\n","trees = dfaveraged_data['trees'].tolist()\n","label = dfaveraged_data['label'].tolist()\n","\n","\n","\n","countME =0\n","countAE=0\n","countMNE=0\n","countANE=0\n","\n","#On décompte le nombre d'arbres éteints pour chaque couple (action, état)\n","\n","for k in range(len(mode)):\n","    if mode[k]==0 and label[k]==1:\n","        R[0,0]+=trees[k]\n","        countME+=1\n","    if mode[k]==0 and label[k]==0:\n","         R[0,1]+=trees[k]\n","         countMNE+=1\n","    if mode[k]==1 and label[k]==1:\n","         R[1,0]+=trees[k]\n","         countAE+=1\n","    if mode[k]==1 and label[k]==0:\n","         R[1,1]+=trees[k]\n","         countANE+=1\n","        \n","#Puis on fait la moyenne\n","\n","R[0,0]=R[0,0]/countME\n","R[0,1]=R[0,1]/countMNE\n","R[1,0]=R[1,0]/countAE\n","R[1,1]=R[1,1]/countANE\n","\n","\n","\n","print(R)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"E5FPAaB9Jvb-"},"source":["**1.2.2. State a necessary condition on reward function to enable a non trivial POMDP optimization.**\n","\n","For instance, what is the issue if r(s,manual) = r(s,auto) $\\forall s \\in S$"]},{"cell_type":"markdown","metadata":{"id":"h1XXrVV9Jvb_"},"source":["#Answer: Si r(s,manual) = r(s,auto) pour tout s, impossible de distinguer une bonne action d'une mauvaise : la stratégie adoptée sera donc aléatoire. \n","Une condition nécessaire pour éviter une stratégie aléatoire est d'avoir r(s,manual) != r(s,auto) pour tout s. Ainsi, dans un état donné, l'algo peut distinguer la meilleure action à entreprendre."]},{"cell_type":"markdown","metadata":{"id":"8Xw924ZFJvb_"},"source":["\n","**1.2.3. Verify with descriptive statistics that the reward function changes with respect to state and action.**\n","\n","* **Is the score (number of extinguished trees) evolving differently with respect to the robot operation mode and human operator engagement (described by her/his mission performance)?**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bw1mqgJ3Jvb_","outputId":"034db3c4-7897-403a-9f6f-3ae9ff2ff893"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0.55484027 0.28190895]\n"," [0.41760041 0.35650864]]\n"]}],"source":["## get a look on how the number of fires extinguished  evolves\n","## in function of the operation mode and mission performance\n","## use plotting_data_per_mode function given in the begining of this notebook\n","\n","# we can also plot the frequency (or the expected number)\n","\n","#Réponse : \n","\n","print(R)\n","plotting_data_per_mode(dfaveraged_data, \"label\", \"trees\")\n","\n","#La fonction de reward R codée en 1.2.1 montre que les récompenses évoluent en fonction de l'état et de l'action entreprise (les coefficients de la matrice étant tous différents).\n","#Cependant, on remarque que r(ne, manual)=6.22 est proche de r(ne, auto) ce qui, comme évoqué dans la question précédente, peut induire \n","#une décision d'action relativement aléatoire dans le cas d'un étant non engagé.\n","\n","#"]},{"cell_type":"markdown","metadata":{"id":"JF--LeoDJvb_"},"source":["**1.2.4. Please identify the greedy action $a \\in A = \\{manual, auto\\}$ (\"autonomous robot mode\" or \"manual mode\") for each hidden system state $s \\in S = \\{e, ne\\}$ (\"engagement\" or \"no engagement\").** \n","\n","Describe then the behavior of the artificial agent suggested by this reward function."]},{"cell_type":"markdown","metadata":{"id":"mKVWMtCGJvb_"},"source":["Answer:En s'intéressant à la première colonne de la matrice de reward, 16>12 donc dans un état engagé, la fonction tend à passer en manuel.\n","En s'intéressant à la seconde colonne de la matrice de reward, 7>6.22 donc dans un état désengagé, la fonction tend à passer en automatique."]},{"cell_type":"markdown","metadata":{"id":"8G6nkhtGJvb_"},"source":["## Task 2: POMDP model solving and evaluation"]},{"cell_type":"markdown","metadata":{"id":"J9MAhfxqJvb_"},"source":["### Task 2.1: POMDP model description using the Cassandra format\n","\n","In this task, please use the Cassandra format to decribe the POMDP model, in a way that the PyPOMDP library can interpret it and solve the problem.\n","\n","You can use the tiger-2D problem located at *.PyPOMDP/pypomdp/environments/pomdp/Tiger-2D.POMDP* as an example.\n","\n","Please save the created model in the same folder as the *Tiger-2D.POMDP*, and copy/paste your Cassandra file in the cell bellow:"]},{"cell_type":"markdown","metadata":{"id":"gefMCYTfJvcA"},"source":["Answer:\n","\n","#### EXAMPLE : Firefighter POMDP problem description in Cassandra format \n","\n","# Firefighter robot POMDP description in Cassandra format\n","\n","\n","\n","\n","discount: 0.95\n","\n","values: reward\n","\n","states: notengaged engaged \n","\n","actions: manu auto\n","\n","observations: onotengaged oengaged\n","\n","start: 0.5 0.5\n","\n","T: manu\n","0.98 0.02\n","0.02 0.98\n","\n","T: auto\n","0.98 0.02\n","0.02 0.98\n","\n","O: manu\n","0.4146 0.5854\n","0.1355 0.8645\n","\n","O: auto\n","0.4146 0.5854\n","0.1355 0.8645\n","\n","\n","R: manu : oengaged : * : * 0.55484027\n","\n","R: manu : onotengaged : * : * 0.28190895\n","\n","R: auto : oengaged : * : * 0.41760041\n","\n","R: auto : onotengaged : * : * 0.35650864\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"V6IX-xxVJvcA"},"source":["### Task 2.2: POMDP model solving using the customized PyPOMDP library "]},{"cell_type":"markdown","metadata":{"id":"QLTO0anMJvcA"},"source":["To solve the problem using the PyPOMDP library, you need to open a new terminal in the same folder as your jupyter-notebook.\n","\n","Then, go to the folder .PyPOMDP/pypomdp/ and launch the following command line:\n","\n","**python main.py pbvi --env Firefighter-2D.POMDP --logfile logFIREpbvi --option offsolve**\n","\n","where:\n","\n","pbvi is the algorithm to be used\n","\n","--env : gives the pomdp file name of your model\n","\n","--logfile : save the traces of policy computation and simulation (only one simulation)\n","\n","--option : offline or online solving, or simulate a policy file\n","\n","\n","*Note a file called **alphavecfile.policy** is created. Please save this file with a more explicit name.*\n","\n","This file will be useful in the following steps."]},{"cell_type":"markdown","metadata":{"id":"Y8FE5TbGJvcA"},"source":["### Task 2.3: POMDP model evaluation in simulation"]},{"cell_type":"markdown","metadata":{"id":"9cFd6kCcJvcA"},"source":["To evaluate the value function and policy obtained, you need to go back to the terminal and launch the following command line:\n","\n","**python main.py pbvi --env Firefighter-2D.POMDP --policyfile alphavecfile.policy --logfile logFIREpbvi --max_play 60 --option simulate --sim 500**\n","\n","\n","where:\n","\n","pbvi is the used algorithm\n","\n","--env : gives the pomdp file name of your model\n","\n","--logfile : save the traces of policy computation and simulation (only one simulation)\n","\n","--option simulate : simulate a policy using the model\n","\n","--policyfile : your policy file, default: alphavecfile.policy\n","\n","--max_play :  (60 steps = 10 minutes = 1 mission, following the the 10s-step time assumption)\n","\n","*Note that you will find a file named **YEAR-MONTH-DAY-H-MIN-S** in the logFile folder (\"logFIREpbvi\" here). Please have a look at this file to follow the performed simulations. At the end of this file there is a vector with all total rewards observed during the different simulations.*"]},{"cell_type":"markdown","metadata":{"id":"o2WrR7FlJvcA"},"source":["**Please copy and paste policy simulation average results hereafter (what appears in the terminal):**\n"]},{"cell_type":"markdown","metadata":{"id":"G6ayYeBLJvcA"},"source":["Answer:\n","500 simulations played.\n","Exp total reward =  25.335703400000014\n","Std Exp total reward =  0.8725609162737235"]},{"cell_type":"markdown","metadata":{"id":"5ZwPG_OpJvcB"},"source":["### Task 2.4 : Quantitative and qualitative comparison with the random policy used during experiments\n","\n","In the following, another preprocessed dataset is given: **averagedPMPV_data.csv.** This dataset includes the global_score reached by each participant for each mission.\n","\n","#### Task 2.4.1: Quantitative comparison\n","\n","1. Compute the average number of trees extinguished following the random policy used during the experiments\n","2. Compare this results with the observed results (total_rewards) at least 72 simulations of 60 steps (which is equivalent to 18 participants x 4 mission)\n","3. Perform a statistical test to verify if the value reached by the optimized policy is significatively greater.\n","\n","**Remark**: we could also compute the expected value of a random policy on the POMDP model defined. To do this used the following command line:\n","\n","**python main.py pbvi --env Firefighter-2D.POMDP --logfile logFIREpbvi --max_play 60 --option simulate --sim 500 --random_policy 1**\n","\n","Note that this expected value can differs from the one obtained from dataset. Why?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ljL5OOXTJvcB","outputId":"bee544a7-da08-48b5-a780-ca852a2778f8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Avg. global scores from dataset :  22.083333333333332\n","Avg. global scores from simulations :  nan\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\willi\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3334: RuntimeWarning: Mean of empty slice.\n","  return _methods._mean(a, axis=axis, dtype=dtype,\n","C:\\Users\\willi\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n","  ret = ret.dtype.type(ret / rcount)\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as mpatches\n","import seaborn as sns\n","from scipy.stats import ttest_ind\n","\n","## Computing the average number of trees extinghuised following the random policy used during the experiments\n","#################################\n","# importing data\n","dfaveraged_data = pd.read_csv('./data/averagedPMPV_data.csv')\n","dfaveraged_data.columns\n","print(\"Avg. global scores from dataset : \", np.mean(dfaveraged_data[\"global_score\"]))\n","\n","##################################\n","### copy the total rewards observed on your 72 simulations here\n","pomdp_obs_ttrew = [ ]\n","print(\"Avg. global scores from simulations : \", np.mean(pomdp_obs_ttrew))\n","\n","##################################\n","### perform a statistical test to check the hypothesis:\n","## H0 : the mean score from dataset is equal to the mean score obtained from policy simulations\n","## H1 : the mean score from dataset is different to the mean score obtained from policy simulations\n","\n","### perform a second statistical test to check the hypothesis:\n","## H0 : the mean score from dataset is higher than the mean score obtained from policy simulations\n","## H1 : the mean score from dataset is not higher than the mean score obtained from policy simulations\n","\n"]},{"cell_type":"markdown","metadata":{"id":"5JW3hSDjJvcB"},"source":["**Draw your conclusion here :** "]},{"cell_type":"markdown","metadata":{"id":"eYwmaawDJvcB"},"source":["Answer:"]},{"cell_type":"markdown","metadata":{"id":"unnLDWCfJvcB"},"source":["### Task 2.4.2: Qualitative comparison by performing a replay with collected data\n","\n","Save the classifier model you have designed. It will be used by a replay runner to rerun a mission.\n","\n","Our goal is to : \n","1. follow the predictor outputs (the POMDP observations)\n","2. visualize the belief state updates about the human operator's engagement\n","3. check and describe what the POMDP policy would do given the current belief state"]},{"cell_type":"markdown","metadata":{"id":"oPOn_QrhJvcB"},"source":["***1. Save your the classifier model***\n","\n","see https://scikit-learn.org/stable/modules/model_persistence.html"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-SWJUM2-JvcB"},"outputs":[],"source":["from joblib import dump, load\n","\n","#########################################\n","# save the model named: classifier.joblib\n","\n"]},{"cell_type":"markdown","metadata":{"id":"OXALKHzGJvcC"},"source":["Now, save this classifier.joblib file in \"PyPOMDP/pypompd/data/\" folder, and\n","\n","***2. Run the replay program in the same terminal as before***\n","\n","Note you may choose a subject file (one of the excluded participants for instance) to replay the experiment.\n","\n","For that, see this command line example:\n","\n","**python replay.py pbvi --env Firefighter-2D.POMDP --policyfile alphavecfile.policy --logfile logFIREpbvi --max_play 60 --option replay --sim 4 --expfile data/dfsub_33alldataproc.csv --classif YOUR_CLASSIFIER_MODEL --fnames THE_FEATURES_NAMES_YOU_USED**\n","\n","where THE_FEATURES_NAMES_YOU_USED can be for instance 'mode,nav,tank,nbAOI1', and YOUR_CLASSIFIER_MODEL something like 'data/classifier.joblib'.\n","You may get a look in the log folder. \n","\n","The last logfile details the sequence of symbolic observations predicted from the selected features of the participant."]},{"cell_type":"markdown","metadata":{"id":"twaH_jWFJvcC"},"source":["***3. Describe what the POMDP policy seems to do given the current belief state***\n","\n","**Draw your conclusions here:**"]},{"cell_type":"markdown","metadata":{"id":"Bnqq7uljJvcC"},"source":["Answer:"]},{"cell_type":"markdown","metadata":{"id":"yz_kJ6deJvcC"},"source":["## Task 3 : Refining the POMDP model"]},{"cell_type":"markdown","metadata":{"id":"IbPJIE_aJvcC"},"source":["### Refine the POMDP model to integrate a visible state variable $s_r$ to indicate the operation mode of the robot as part of the state\n","\n","In this task, the aim is to expand the state spape $S$ such as: $S = S_h \\times S_r$, with $S_h=\\{e, ne\\}$ and $S_r=\\{manu,auto\\}$, and to conditionnate the observation function with respect to the action taken.\n","\n","1. If you observe the replay of experiences, how could you model the fact that when the robot operation mode changes, there is a bigger/lower chance the state of the human operator changes as well ?\n","\n","2. If this fact is taken into account, it may changes the transition function. So, let's consider now two additionnal expert parameters $\\beta$ and $\\eta$ that will express the chance we have to obtain for instance : \n","$$p(s'=(engaged,manual)|s=(engaged,auto),a=manual) = 1-\\beta$$\n","$$p(s'=(notengaged,manual)|s=(engaged,auto),a=manual) = \\beta$$\n","$$p(s'=(engaged,auto)|s=(engaged,manual),a=auto) = 1-\\eta$$\n","$$p(s'=(notengaged,auto)|s=(engaged,manual),a=auto) = \\eta$$\n","\n","Note the transition function, now a $4x4$ matrix, need to be modified to integrate this new parameters. \n","\n","We will assume that the robot operation mode state variable has a deterministic dynamics. It means that when the action $auto$ is chosen, we are $100\\%$ sure that the operation mode switches to $auto$.\n","\n","If you have any problem with the grammar of the POMDP file description, please get a look at https://www.pomdp.org/code/pomdp-file-spec.html\n","\n","3. Note, you can learn an observation function now conditionned on the action, to be able to integrate this new probabilities through belief state updates, i.e. : $b^o_a(s') \\propto p(o|s',a)p(s'|s,a)b(s)$ \n","\n","4. Please revise some of the previous tasks in the cells bellow. "]},{"cell_type":"markdown","metadata":{"id":"1ipWQatRJvcC"},"source":["### Task 3.1. Revise task 1.1.3 to separate your dataset in two datasets depending on the robot operation mode "]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"id":"7yxX7lJzJvcC","outputId":"1363a09f-039b-4862-d623-80a32e3c1f88"},"outputs":[{"ename":"SyntaxError","evalue":"invalid syntax (<ipython-input-12-f7598a1ab535>, line 22)","output_type":"error","traceback":["\u001b[1;36m  File \u001b[1;32m\"<ipython-input-12-f7598a1ab535>\"\u001b[1;36m, line \u001b[1;32m22\u001b[0m\n\u001b[1;33m    subsubdataset_manu = ?\u001b[0m\n\u001b[1;37m                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"]}],"source":["import pandas as pd\n","import numpy as np\n","\n","##############################\n","# importing data\n","df10labeled_data = pd.read_csv('./data/df10labeled_data.csv')\n","print(df10labeled_data)\n","\n","##############################\n","## excluding some subjects as before\n","## we empirically choose to exclude subjects 19, 23, 33, 38\n","subdf10labeled_data = df10labeled_data.loc[(df10labeled_data[\"subject\"]!=19)&\n","                                           (df10labeled_data[\"subject\"]!=23)&\n","                                           (df10labeled_data[\"subject\"]!=33)&\n","                                           (df10labeled_data[\"subject\"]!=38)]\n","print(subdf10labeled_data)\n","\n","######################################################\n","# separate the dataset with respect to operation mode\n","# and select the features to be used for classification\n","\n","\n","subsubdataset_manu = ?\n","\n","subsubdataset_auto = ?\n","\n"]},{"cell_type":"markdown","metadata":{"id":"bzyvfRoCJvcC"},"source":["### Task 3.2. Revise tasks 1.1.4 and 1.1.5 to train a classifier per dataset and then, extract their confusion matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FXwK3XDjJvcD"},"outputs":[],"source":["#### PUT YOUR CODE HERE"]},{"cell_type":"markdown","metadata":{"id":"sJVzwVQwJvcD"},"source":["### Task 3.3. Revise task 2.1 to define your POMDP in the Cassandra file format\n","\n","Note you may probably have different transition and observations functions depending on the action manu/auto.\n","\n","Copy and paste your POMDP model in Cassandra format hereafter:"]},{"cell_type":"markdown","metadata":{"id":"vuAMzA19JvcD"},"source":["\n","### Firefighter.4D.POMDP\n","\n","discount: 0.95\n","\n","values: reward\n","\n","states: notengagedmanu engagedmanu notengagedauto engagedauto \n","\n","actions: manu auto\n","\n","observations: onotengaged oengaged\n","\n","start: 0.25 0.25 0.25 0.25\n","\n","..."]},{"cell_type":"markdown","metadata":{"id":"FISa_zGxJvcD"},"source":["### Task 3.4. Revise tasks 2.2 and 2.3"]},{"cell_type":"markdown","metadata":{"id":"z_k3ZNrCJvcD"},"source":["#### Copy and paste the used command lines for POMDP solving and the results obtained with 500 simulations for this new POMDP model and optimized policy\n"]},{"cell_type":"markdown","metadata":{"id":"3IKwuBRjJvcD"},"source":["Answer:"]},{"cell_type":"markdown","metadata":{"id":"sszP5XidJvcD"},"source":["## Champions' Question:\n","\n","**Is this new POMDP model presenting a significant improvement according to the expected cumulated rewards when compared with the random policy used during experiments?**\n","\n","\n","**Is this new POMDP model presenting a significant improvement according to the expected cumulated rewards when compared with the policy optimized based on the previous POMDP model?**"]},{"cell_type":"markdown","metadata":{"id":"vvQqdwdCJvcD"},"source":["Answer:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qBjwaez5JvcD"},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"BE_Firefighter_Robot_Game_Useful.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}